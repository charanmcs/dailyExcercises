{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Pipeline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWoOYWQT9VbWkRD5+XEgHq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HZZ2OeLw9Wgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0550aebe-9917-4561-9fdf-ceed22dc6350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.1.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.7.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.15)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Collecting en-core-web-lg==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.2.0/en_core_web_lg-3.2.0-py3-none-any.whl (777.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 777.4 MB 6.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.2.0) (3.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.4.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.64.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (21.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.15)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.9.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.7.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.21.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.25.11)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "  Attempting uninstall: en-core-web-lg\n",
            "    Found existing installation: en-core-web-lg 2.1.0\n",
            "    Uninstalling en-core-web-lg-2.1.0:\n",
            "      Successfully uninstalled en-core-web-lg-2.1.0\n",
            "Successfully installed en-core-web-lg-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "Requirement already satisfied: textacy in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.1.0)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (3.2.4)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.4)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.6.3)\n",
            "Requirement already satisfied: pyphen>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.12.0)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.64.0)\n",
            "Requirement already satisfied: cytoolz>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.11.2)\n",
            "Requirement already satisfied: jellyfish>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.21.5)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.10.1->textacy) (0.11.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.25.11)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->textacy) (3.1.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.6.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (21.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.7)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (7.1.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.9.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (8.0.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.7.7)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.10.0.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->textacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.0->textacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.0->textacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "!pip install textacy\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import nltk\n",
        "import textacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=spacy.load('en_core_web_lg')\n",
        "f = open('text.txt','rt')\n",
        "data = f.read()"
      ],
      "metadata": {
        "id": "ln9bSiMem__m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sentence Segmentation"
      ],
      "metadata": {
        "id": "0gCB4TaxpBhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "sentences=nltk.sent_tokenize(data)\n",
        "for i in range(0,5):\n",
        "  try:\n",
        "    print(sentences[i])\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKAGQkDNLNaw",
        "outputId": "d2dffeea-95a7-4d89-f473-5b256a82bd13"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Along with the growth of the internet and big data, making people overwhelmed by the large information and documents on the internet.\n",
            "This triggers the desire of many researchers to develop a technological approach that can summarize texts automatically.\n",
            "Automatic text summarization generates summaries containing important sentences and includes all important relevant information from the original document (Allahyari et al., 2017, Gambhir and Gupta, 2017).\n",
            "So the information quickly arrives and does not lose the original intent of the document (Murad and Martin, 2007).\n",
            "The area of text summarization research has been studied since the mid-20th century, which was first discussed openly by Lun (1958) with a statistical technique namely word frequency diagrams.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Word Tokenization"
      ],
      "metadata": {
        "id": "DKvDpmE6pQpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words=[]\n",
        "for sentence in sentences:\n",
        "  words.append(nltk.word_tokenize(sentence))\n",
        "print(words)"
      ],
      "metadata": {
        "id": "Y9pUC_ZrNA4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcef341-d838-4463-f8cd-e309dfa86391"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Along', 'with', 'the', 'growth', 'of', 'the', 'internet', 'and', 'big', 'data', ',', 'making', 'people', 'overwhelmed', 'by', 'the', 'large', 'information', 'and', 'documents', 'on', 'the', 'internet', '.'], ['This', 'triggers', 'the', 'desire', 'of', 'many', 'researchers', 'to', 'develop', 'a', 'technological', 'approach', 'that', 'can', 'summarize', 'texts', 'automatically', '.'], ['Automatic', 'text', 'summarization', 'generates', 'summaries', 'containing', 'important', 'sentences', 'and', 'includes', 'all', 'important', 'relevant', 'information', 'from', 'the', 'original', 'document', '(', 'Allahyari', 'et', 'al.', ',', '2017', ',', 'Gambhir', 'and', 'Gupta', ',', '2017', ')', '.'], ['So', 'the', 'information', 'quickly', 'arrives', 'and', 'does', 'not', 'lose', 'the', 'original', 'intent', 'of', 'the', 'document', '(', 'Murad', 'and', 'Martin', ',', '2007', ')', '.'], ['The', 'area', 'of', 'text', 'summarization', 'research', 'has', 'been', 'studied', 'since', 'the', 'mid-20th', 'century', ',', 'which', 'was', 'first', 'discussed', 'openly', 'by', 'Lun', '(', '1958', ')', 'with', 'a', 'statistical', 'technique', 'namely', 'word', 'frequency', 'diagrams', '.'], ['Many', 'different', 'approaches', 'have', 'been', 'created', 'to', 'date', '.'], ['Based', 'on', 'the', 'number', 'of', 'the', 'document', ',', 'there', 'is', 'single', 'and', 'multi-document', 'summarization', '.'], ['Meanwhile', ',', 'based', 'on', 'the', 'summary', 'results', 'there', 'are', 'the', 'extractive', 'and', 'abstractive', 'results', '.'], ['A', 'single', 'document', 'produces', 'a', 'summary', 'that', 'is', 'sourced', 'from', 'one', 'source', 'document', '(', 'Radev', 'et', 'al.', ',', '2001', ')', 'and', 'the', 'content', 'described', 'is', 'around', 'the', 'same', 'topic', '.'], ['While', 'the', 'multi-document', 'summarization', 'is', 'taken', 'from', 'various', 'sources', 'or', 'documents', 'that', 'discuss', 'the', 'same', 'topic', '(', 'Qiang', 'et', 'al.', ',', '2016', ',', 'Ansamma', 'et', 'al.', ',', '2017', ',', 'Widjanarko', 'et', 'al.', ',', '2018', ')', '.'], ['(', 'Christian', 'et', 'al.', ',', '2016', ')', 'made', 'text', 'summarizing', 'in', 'a', 'single', 'document', 'using', 'TF-IDF', 'and', '(', 'Sarkar', ',', '2013', ')', 'designed', 'automatic', 'text', 'summarizing', 'in', 'a', 'single', 'document', 'using', 'the', 'Main', 'Concepts', '.'], ['(', 'Qiang', 'et', 'al.', ',', '2016', ')', 'summarized', 'multiple', 'documents', 'by', 'the', 'pattern-based', 'summarization', '(', 'Patsum', ')', 'method', 'on', 'the', '2004', 'DUC', 'dataset', 'and', 'showed', 'that', 'the', 'results', 'outperformed', 'not', 'only', 'the', 'term-based', 'method', 'but', 'also', 'the', 'ontology-based', 'method', '.'], ['Ansamma', 'et', 'al', '.'], ['(', '2017', ')', 'summarized', 'multiple', 'documents', 'using', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'and', 'Non-Negative', 'Matrix', 'Factorization', '(', 'NMF', ')', 'and', 'the', 'results', 'outperformed', 'the', 'state', 'of', 'the', 'art', 'in', 'precision', 'and', 'recall', '.'], ['Qaroush', 'et', 'al', '.'], ['(', '2019', ')', 'proposes', 'the', 'summarization', 'of', 'the', 'Arabic', 'single', 'document', 'which', 'produces', 'a', 'fairly', 'informative', 'extractive', 'summary', 'combining', 'machine', 'learning', 'and', 'score-based', 'approaches', 'that', 'evaluate', 'each', 'sentence', 'based', 'on', 'a', 'combination', 'of', 'semantics', 'and', 'statistics', '.'], ['The', 'results', 'are', 'superior', 'in', 'terms', 'of', 'precision', 'metrics', ',', 'memory', ',', 'and', 'F-scores', ',', 'the', 'disadvantage', 'is', 'that', 'it', 'has', 'not', 'optimized', 'the', 'weight', 'of', 'the', 'features', '.'], ['Verma', 'and', 'Om', '(', '2019', ')', 'minimized', 'redundancy', 'in', 'multi-document', 'summarizing', 'by', 'the', 'Shark', 'Smell', 'Optimization', '(', 'SSO', ')', 'method', 'and', 'the', 'performance', 'results', 'were', 'far', 'better', 'than', 'the', 'previous', 'summary', 'method', '.'], ['Extractive', 'summarization', 'is', 'a', 'summary', 'that', 'summaries', 'consist', 'entirely', 'of', 'extracted', 'content', 'so', 'that', 'the', 'results', 'of', 'summary', 'sentences', 'are', 'sentences', 'or', 'words', 'obtained', 'from', 'the', 'original', 'text', '(', 'Khan', 'and', 'Salim', ',', '2014', ')', '.'], ['The', 'usual', 'problem', 'raised', 'from', 'the', 'extractive', 'summarization', 'research', 'at', 'first', 'was', 'determining', 'the', 'position', 'of', 'the', 'sentence', '(', 'Khan', 'and', 'Salim', ',', '2014', ')', 'and', 'the', 'frequency', 'of', 'words', 'in', 'the', 'text', '(', 'Baxendale', ',', '1958', ')', '.'], ['The', 'next', 'experiment', 'raised', 'the', 'extraction', 'problem', 'which', 'is', 'known', 'as', 'the', 'Information', 'Extraction', '(', 'IE', ')', 'technique', 'to', 'produce', 'a', 'summary', 'with', 'more', 'specific', 'results', 'and', 'to', 'increase', 'accuracy', '.'], ['One', 'example', 'of', 'an', 'automatic', 'summarizing', 'system', 'that', 'has', 'been', 'developed', 'by', 'adopting', 'IE', 'techniques', 'is', 'RIPTIDES', ',', 'which', 'functions', 'to', 'summarize', 'news', 'based', 'on', 'scenarios', 'chosen', 'by', 'the', 'user', '(', 'White', 'et', 'al.', ',', '2001', ')', '.'], ['Research', 'by', 'Naik', 'and', 'Gaonkar', '(', '2017', ')', 'using', 'a', 'rule', 'base', 'produces', 'the', 'best', 'average', 'precision', ',', 'f-measure', ',', 'and', 'recall', 'values', 'for', 'Rule-Based', 'Summarizers', 'but', 'has', 'not', 'yet', 'been', 'tried', 'on', 'broader', 'data', '.'], ['Furthermore', ',', 'there', 'are', 'extractive', 'summarizing', 'studies', 'using', 'neural', 'networks', ',', 'which', 'in', 'recent', 'years', 'have', 'achieved', 'greater', 'popularity', 'than', 'conventional', 'approaches', ',', 'some', 'of', 'these', 'studies', 'are', '(', 'Mohsen', 'et', 'al.', ',', '2020', ',', 'Anand', 'and', 'Wagh', ',', '2019', ',', 'Xu', 'and', 'Durrett', ',', '2019', ',', 'Chen', 'et', 'al.', ',', '2018a', ',', 'Chen', 'et', 'al.', ',', '2018b', ',', 'Alami', 'et', 'al.', ',', '2019', ')', '.'], ['Research', 'conducted', 'by', 'Anand', 'and', 'Wagh', '(', '2019', ')', 'used', 'a', 'deep', 'learning', 'technique', 'namely', 'Feed', 'Forward', 'Neural', 'Network', '(', 'FFNN', ')', 'to', 'summarize', 'a', 'single', 'document', 'in', 'a', 'legal', 'document', 'that', 'has', 'the', 'advantage', 'of', 'producing', 'an', 'extractive', 'summary', 'without', 'the', 'need', 'to', 'create', 'features', 'or', 'domain', 'knowledge', 'and', 'perform', 'well', 'as', 'measured', 'by', 'the', 'Rouge', 'score', 'and', 'produces', 'a', 'coherent', 'summary', ',', 'will', 'but', 'weak', 'in', 'terms', 'of', 'simplifying', 'complex', 'and', 'long', 'sentences', '.'], ['In', 'contrast', 'to', 'extractive', 'summarization', ',', 'sentences', 'generated', 'by', 'abstractive', 'summaries', 'are', 'new', 'sentences', 'or', 'commonly', 'called', 'paraphrases', 'which', 'produce', 'summaries', 'using', 'words', 'that', 'are', 'not', 'in', 'the', 'text', '.'], ['Abstractive', 'summaries', 'are', 'very', 'complex', 'and', 'relatively', 'more', 'difficult', 'than', 'extractive', 'summaries', 'because', 'producing', 'abstractive', 'summaries', 'requires', 'extensive', 'natural', 'language', 'processing', '(', 'Gambhir', 'and', 'Gupta', ',', '2017', ')', '.'], ['Approach', 'techniques', 'in', 'abstractive', 'summary', 'are', 'generally', 'grouped', 'into', 'two', 'categories', 'namely', 'the', 'linguistic', 'approach', 'and', 'the', 'semantic', 'approach', '.'], ['Examples', 'of', 'methods', 'that', 'use', 'linguistic', 'approaches', 'such', 'as', 'information-based', 'methods', '(', 'Genest', 'and', 'Lapalme', ',', '2012', ')', 'and', 'tree-based', 'methods', '(', 'Barzilay', 'et', 'al.', ',', '1999', ',', 'Tanaka', 'et', 'al.', ',', '2009', ')', '.'], ['While', 'examples', 'of', 'methods', 'that', 'use', 'semantic', 'approaches', 'such', 'as', 'template-based', 'methods', '(', 'Genest', 'and', 'Lapalme', ',', '2011', ')', 'and', 'ontology-based', 'methods', '(', 'Chang-Shing', 'et', 'al.', ',', '2005', ')', '.'], ['More', 'recently', 'research', 'on', 'abstractive', 'summarizing', 'has', 'been', 'inspired', 'by', 'the', 'encoder-decoder', 'framework', ',', 'as', 'in', 'research', 'conducted', 'by', 'Xu', 'et', 'al', '.'], ['(', '2020', ')', ';', 'Lee', 'et', 'al', '.'], ['(', '2020', ')', ';', 'Yao', 'et', 'al', '.'], ['(', '2018a', ')', ';', 'Iwasaki', 'et', 'al', '.'], ['(', '2019', ')', '.'], ['Besides', 'being', 'believed', 'that', 'this', 'model', 'is', 'smoother', ',', 'the', 'encoder-decoder', 'framework', 'is', 'also', 'convenient', 'in', 'adjusting', 'parameters', 'automatically', '(', 'Xu', 'et', 'al.', ',', '2020', ')', '.'], ['In', 'the', '2000s', ',', 'there', 'was', 'a', 'renewed', 'trend', 'in', 'the', 'field', 'of', 'text', 'summarizing', 'research', '.'], ['Summaries', 'are', 'not', 'only', 'generated', 'once', 'but', 'are', 'also', 'able', 'to', 'summarize', 'events', 'in', 'real-time', 'or', 'update', 'summaries', 'when', 'new', 'information', 'appears', 'called', 'real-time', 'summarization', '(', 'Ekstrand-abueg', 'et', 'al.', ',', '2016', ',', 'Lou', 'and', 'Man', ',', '2012', ',', 'H', ',', 'A.S.S.', ',', 'K', ',', 'M.M.C.', ',', ',', '2016', ',', 'Maio', 'et', 'al.', ',', '2015', ',', 'Rodríguez-Vidal', 'et', 'al.', ',', '2019', ',', 'Kacprzyk', 'et', 'al.', ',', '2008', ',', 'Fu', 'et', 'al.', ',', '2015', ',', 'Wu', 'et', 'al.', ',', '2015a', ',', 'Wu', 'et', 'al.', ',', '2015b', ',', 'Wang', 'et', 'al.', ',', '2014', ')', '.'], ['Approach', 'techniques', 'that', 'have', 'been', 'used', 'in', 'real-time', 'summarization', 'are', 'fuzzy-based', 'and', 'machine', 'learning', '.'], ['An', 'example', 'of', 'a', 'method', 'that', 'uses', 'a', 'fuzzy-based', 'approach', 'is', 'the', 'fuzzy', 'logic', 'with', 'classic', 'Zadeh', \"'s\", 'calculus', 'of', 'linguistically', 'quantified', 'propositions', '(', 'Kacprzyk', 'et', 'al.', ',', '2008', ')', 'which', 'addresses', 'trend', 'extraction', 'and', 'real-time', 'problems', 'where', 'the', 'results', 'are', 'superior', 'in', 't-norm', 'evaluation', ',', 'but', 'weak', 'in', 'semantic', 'problems', 'because', 'the', 'semantic', 'results', 'of', 'other', 't-norms', 'are', 'unclear', 'and', 'unclear', 'can', 'be', 'understood', '.'], ['Fuzzy', 'Formal', 'Concept', 'Analysis', '(', 'Fuzzy', 'FCA', ')', '(', 'Maio', 'et', 'al.', ',', '2015', ')', 'which', 'addresses', 'semantic', 'and', 'real', 'time', 'problems', 'where', 'the', 'results', 'excel', 'at', 'evaluations', 'in', 'f-measures', 'with', 'optimal', 'recall', 'and', 'comparable', 'precision', '.'], ['An', 'example', 'of', 'a', 'method', 'that', 'uses', 'a', 'machine', 'learning', 'approach', 'is', 'Incremental', 'Short', 'Text', 'Summarization', '(', 'IncreSTS', ')', 'by', 'Liu', 'et', 'al.', ',', '2015a', ',', 'Liu', 'et', 'al.', ',', '2015b', 'which', 'has', 'better', 'outlier', 'handling', ',', 'high', 'efficiency', ',', 'and', 'scalability', 'on', 'target', 'problems', '.'], ['Rank-biased', 'precision-summarization', '(', 'RBP-SUM', ')', 'by', 'Rodríguez-Vidal', 'et', 'al', '.'], ['(', '2019', ')', 'which', 'has', 'advantages', 'in', 'overcoming', 'redundancy', 'by', 'evaluating', 'using', 'rouge', ',', 'but', 'this', 'method', 'can', 'only', 'produce', 'extractive', 'summaries', '.'], ['Text', 'summarization', 'is', 'a', 'formidable', 'challenge', 'in', 'the', 'field', 'of', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', '(', 'Rane', 'and', 'Govilkar', ',', '2019', ',', 'Shabbir', 'Moiyadi', 'et', 'al.', ',', '2016', ')', 'because', 'it', 'requires', 'precise', 'text', 'analysis', 'such', 'as', 'semantic', 'analysis', 'and', 'lexical', 'analysis', 'to', 'produce', 'a', 'good', 'summary', '.'], ['A', 'good', 'summary', ',', 'in', 'addition', ',', 'must', 'contain', 'important', 'information', 'and', 'must', 'be', 'concise', 'but', 'also', 'must', 'consider', 'aspects', 'such', 'as', 'non-redundancy', ',', 'relevance', ',', 'coverage', ',', 'coherence', ',', 'and', 'readability', '(', 'Verma', 'et', 'al.', ',', '2019', ')', '.'], ['Where', 'to', 'get', 'all', 'these', 'aspects', 'in', 'a', 'summary', 'is', 'a', 'great', 'challenge', '.'], ['The', 'review', 'of', 'papers', 'on', 'text', 'summarization', 'is', 'important', 'because', 'summarizing', 'extractive', 'techniques', 'has', 'become', 'a', 'very', 'broad', 'research', 'topic', 'and', 'is', 'heading', 'towards', 'maturity', '(', 'Gupta', 'and', 'Gupta', ',', '2019', ')', '.'], ['Now', 'research', 'has', 'shifted', 'towards', 'abstractive', 'summarization', '(', 'Gupta', 'and', 'Gupta', ',', '2019', ')', 'and', 'real-time', 'summarization', '.'], ['This', 'is', 'because', 'abstractive', 'summaries', 'are', 'more', 'complex', 'and', 'complicated', 'than', 'extractive', 'summaries', '.'], ['So', 'extractive', 'summaries', 'are', 'easier', 'to', 'give', 'expected', 'and', 'better', 'results', 'than', 'abstractive', 'summaries', '(', 'Elrefaiy', 'et', 'al.', ',', '2018', ',', 'Allahyari', 'et', 'al.', ',', '2017', ',', 'Mishra', 'and', 'Gayen', ',', '2018', ')', '.'], ['However', ',', 'extractive', 'summarization', 'is', 'also', 'still', 'in', 'great', 'demand', 'as', 'evident', 'extractive', 'research', 'still', 'exists', 'in', 'the', 'last', 'two', 'years', '(', 'Ren', 'et', 'al.', ',', '2018', ',', 'Sanchez-gomez', 'et', 'al.', ',', '2018', ',', 'Yao', 'et', 'al.', ',', '2018b', ',', 'Khan', 'et', 'al.', ',', '2019', ',', 'Qaroush', 'et', 'al.', ',', '2019', ',', 'Anand', 'and', 'Wagh', ',', '2019', ',', 'Lierde', 'and', 'Chow', ',', '2019', ')', '.'], ['This', 'indicates', 'the', 'possibility', 'that', 'there', 'are', 'still', 'opportunities', 'or', 'loopholes', 'to', 'improve', '.'], ['A', 'clear', 'literature', 'study', 'is', 'demanded', 'as', 'a', 'means', 'for', 'the', 'advancement', 'of', 'research', 'in', 'the', 'field', 'of', 'text', 'summarization', '.'], ['Where', 'literature', 'studies', 'are', 'generally', 'contained', ',', 'analyzed', ',', 'and', 'compared', 'in', 'a', 'review', 'or', 'survey', 'paper', '.'], ['Review', 'paper', 'made', 'by', 'Gupta', 'and', 'Gupta', '(', '2019', ')', 'discusses', 'popular', 'components', 'specifically', 'about', 'abstractive', 'summarizing', ',', 'such', 'as', 'research', 'trends', 'in', 'the', 'field', 'of', 'abstractive', 'summarization', ',', 'general', 'description', 'of', 'existing', 'abstractive', 'summarizing', 'techniques', ',', 'tools', ',', 'and', 'evaluations', '.'], ['Other', 'reviews', 'were', 'conducted', 'by', 'Abualigah', 'et', 'al', '.'], ['(', '2020', ')', 'gave', 'a', 'brief', 'survey', 'of', 'the', 'techniques', 'of', 'text', 'summarization', 'and', 'specifically', 'in', 'Arabic', '.'], ['A', 'survey', 'conducted', 'by', 'Nazari', 'and', 'Mahdavi', '(', '2018', ')', 'discussing', 'text', 'summarization', 'focuses', 'on', 'the', 'approach', 'techniques', 'and', 'methods', 'used', 'in', 'text', 'summarization', '.'], ['Nazari', 'and', 'Mahdavi', '(', '2018', ')', 'grouped', 'approaches', 'to', 'statistics', ',', 'machine', 'learning', ',', 'semantic-based', ',', 'and', 'swarm', 'intelligence', '.'], ['Another', 'survey', 'was', 'conducted', 'by', 'Elrefaiy', 'et', 'al', '.'], ['(', '2018', ')', 'which', 'is', 'about', 'summarizing', 'extractive', 'texts', 'that', 'focus', 'on', 'unattended', 'techniques', ',', 'presents', 'a', 'list', 'of', 'strengths', 'and', 'weaknesses', 'in', 'a', 'comparison', 'table', ',', 'alluding', 'to', 'a', 'little', 'about', 'evaluations', 'and', 'future', 'trends', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU3c8r_mdYs5",
        "outputId": "7ddae273-a9c8-413d-b5b7-3dae6034d1e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parts of Speech tagging"
      ],
      "metadata": {
        "id": "-E-RlUYCpaT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words=[]\n",
        "for i in words:\n",
        "  tagged_words.append(nltk.pos_tag(i))"
      ],
      "metadata": {
        "id": "mEi2cljklAr2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lemmatization"
      ],
      "metadata": {
        "id": "R7HMR-_8qg6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "l=WordNetLemmatizer()\n",
        "for i,sent in enumerate(words):\n",
        "  for j,word in enumerate(sent):\n",
        "    if(words[i][j].lower()=='was'):\n",
        "      words[i][j]='be'\n",
        "    else:\n",
        "      words[i][j] = l.lemmatize(word)\n",
        "print(words)\n",
        "\n",
        "#was is getting converted to wa its an exception to watch out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ITh5BqOqgMJ",
        "outputId": "25756b9c-6af2-41c4-a560-f96e2efc73c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[['Along', 'with', 'the', 'growth', 'of', 'the', 'internet', 'and', 'big', 'data', ',', 'making', 'people', 'overwhelmed', 'by', 'the', 'large', 'information', 'and', 'document', 'on', 'the', 'internet', '.'], ['This', 'trigger', 'the', 'desire', 'of', 'many', 'researcher', 'to', 'develop', 'a', 'technological', 'approach', 'that', 'can', 'summarize', 'text', 'automatically', '.'], ['Automatic', 'text', 'summarization', 'generates', 'summary', 'containing', 'important', 'sentence', 'and', 'includes', 'all', 'important', 'relevant', 'information', 'from', 'the', 'original', 'document', '(', 'Allahyari', 'et', 'al.', ',', '2017', ',', 'Gambhir', 'and', 'Gupta', ',', '2017', ')', '.'], ['So', 'the', 'information', 'quickly', 'arrives', 'and', 'doe', 'not', 'lose', 'the', 'original', 'intent', 'of', 'the', 'document', '(', 'Murad', 'and', 'Martin', ',', '2007', ')', '.'], ['The', 'area', 'of', 'text', 'summarization', 'research', 'ha', 'been', 'studied', 'since', 'the', 'mid-20th', 'century', ',', 'which', 'be', 'first', 'discussed', 'openly', 'by', 'Lun', '(', '1958', ')', 'with', 'a', 'statistical', 'technique', 'namely', 'word', 'frequency', 'diagram', '.'], ['Many', 'different', 'approach', 'have', 'been', 'created', 'to', 'date', '.'], ['Based', 'on', 'the', 'number', 'of', 'the', 'document', ',', 'there', 'is', 'single', 'and', 'multi-document', 'summarization', '.'], ['Meanwhile', ',', 'based', 'on', 'the', 'summary', 'result', 'there', 'are', 'the', 'extractive', 'and', 'abstractive', 'result', '.'], ['A', 'single', 'document', 'produce', 'a', 'summary', 'that', 'is', 'sourced', 'from', 'one', 'source', 'document', '(', 'Radev', 'et', 'al.', ',', '2001', ')', 'and', 'the', 'content', 'described', 'is', 'around', 'the', 'same', 'topic', '.'], ['While', 'the', 'multi-document', 'summarization', 'is', 'taken', 'from', 'various', 'source', 'or', 'document', 'that', 'discus', 'the', 'same', 'topic', '(', 'Qiang', 'et', 'al.', ',', '2016', ',', 'Ansamma', 'et', 'al.', ',', '2017', ',', 'Widjanarko', 'et', 'al.', ',', '2018', ')', '.'], ['(', 'Christian', 'et', 'al.', ',', '2016', ')', 'made', 'text', 'summarizing', 'in', 'a', 'single', 'document', 'using', 'TF-IDF', 'and', '(', 'Sarkar', ',', '2013', ')', 'designed', 'automatic', 'text', 'summarizing', 'in', 'a', 'single', 'document', 'using', 'the', 'Main', 'Concepts', '.'], ['(', 'Qiang', 'et', 'al.', ',', '2016', ')', 'summarized', 'multiple', 'document', 'by', 'the', 'pattern-based', 'summarization', '(', 'Patsum', ')', 'method', 'on', 'the', '2004', 'DUC', 'dataset', 'and', 'showed', 'that', 'the', 'result', 'outperformed', 'not', 'only', 'the', 'term-based', 'method', 'but', 'also', 'the', 'ontology-based', 'method', '.'], ['Ansamma', 'et', 'al', '.'], ['(', '2017', ')', 'summarized', 'multiple', 'document', 'using', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'and', 'Non-Negative', 'Matrix', 'Factorization', '(', 'NMF', ')', 'and', 'the', 'result', 'outperformed', 'the', 'state', 'of', 'the', 'art', 'in', 'precision', 'and', 'recall', '.'], ['Qaroush', 'et', 'al', '.'], ['(', '2019', ')', 'proposes', 'the', 'summarization', 'of', 'the', 'Arabic', 'single', 'document', 'which', 'produce', 'a', 'fairly', 'informative', 'extractive', 'summary', 'combining', 'machine', 'learning', 'and', 'score-based', 'approach', 'that', 'evaluate', 'each', 'sentence', 'based', 'on', 'a', 'combination', 'of', 'semantics', 'and', 'statistic', '.'], ['The', 'result', 'are', 'superior', 'in', 'term', 'of', 'precision', 'metric', ',', 'memory', ',', 'and', 'F-scores', ',', 'the', 'disadvantage', 'is', 'that', 'it', 'ha', 'not', 'optimized', 'the', 'weight', 'of', 'the', 'feature', '.'], ['Verma', 'and', 'Om', '(', '2019', ')', 'minimized', 'redundancy', 'in', 'multi-document', 'summarizing', 'by', 'the', 'Shark', 'Smell', 'Optimization', '(', 'SSO', ')', 'method', 'and', 'the', 'performance', 'result', 'were', 'far', 'better', 'than', 'the', 'previous', 'summary', 'method', '.'], ['Extractive', 'summarization', 'is', 'a', 'summary', 'that', 'summary', 'consist', 'entirely', 'of', 'extracted', 'content', 'so', 'that', 'the', 'result', 'of', 'summary', 'sentence', 'are', 'sentence', 'or', 'word', 'obtained', 'from', 'the', 'original', 'text', '(', 'Khan', 'and', 'Salim', ',', '2014', ')', '.'], ['The', 'usual', 'problem', 'raised', 'from', 'the', 'extractive', 'summarization', 'research', 'at', 'first', 'be', 'determining', 'the', 'position', 'of', 'the', 'sentence', '(', 'Khan', 'and', 'Salim', ',', '2014', ')', 'and', 'the', 'frequency', 'of', 'word', 'in', 'the', 'text', '(', 'Baxendale', ',', '1958', ')', '.'], ['The', 'next', 'experiment', 'raised', 'the', 'extraction', 'problem', 'which', 'is', 'known', 'a', 'the', 'Information', 'Extraction', '(', 'IE', ')', 'technique', 'to', 'produce', 'a', 'summary', 'with', 'more', 'specific', 'result', 'and', 'to', 'increase', 'accuracy', '.'], ['One', 'example', 'of', 'an', 'automatic', 'summarizing', 'system', 'that', 'ha', 'been', 'developed', 'by', 'adopting', 'IE', 'technique', 'is', 'RIPTIDES', ',', 'which', 'function', 'to', 'summarize', 'news', 'based', 'on', 'scenario', 'chosen', 'by', 'the', 'user', '(', 'White', 'et', 'al.', ',', '2001', ')', '.'], ['Research', 'by', 'Naik', 'and', 'Gaonkar', '(', '2017', ')', 'using', 'a', 'rule', 'base', 'produce', 'the', 'best', 'average', 'precision', ',', 'f-measure', ',', 'and', 'recall', 'value', 'for', 'Rule-Based', 'Summarizers', 'but', 'ha', 'not', 'yet', 'been', 'tried', 'on', 'broader', 'data', '.'], ['Furthermore', ',', 'there', 'are', 'extractive', 'summarizing', 'study', 'using', 'neural', 'network', ',', 'which', 'in', 'recent', 'year', 'have', 'achieved', 'greater', 'popularity', 'than', 'conventional', 'approach', ',', 'some', 'of', 'these', 'study', 'are', '(', 'Mohsen', 'et', 'al.', ',', '2020', ',', 'Anand', 'and', 'Wagh', ',', '2019', ',', 'Xu', 'and', 'Durrett', ',', '2019', ',', 'Chen', 'et', 'al.', ',', '2018a', ',', 'Chen', 'et', 'al.', ',', '2018b', ',', 'Alami', 'et', 'al.', ',', '2019', ')', '.'], ['Research', 'conducted', 'by', 'Anand', 'and', 'Wagh', '(', '2019', ')', 'used', 'a', 'deep', 'learning', 'technique', 'namely', 'Feed', 'Forward', 'Neural', 'Network', '(', 'FFNN', ')', 'to', 'summarize', 'a', 'single', 'document', 'in', 'a', 'legal', 'document', 'that', 'ha', 'the', 'advantage', 'of', 'producing', 'an', 'extractive', 'summary', 'without', 'the', 'need', 'to', 'create', 'feature', 'or', 'domain', 'knowledge', 'and', 'perform', 'well', 'a', 'measured', 'by', 'the', 'Rouge', 'score', 'and', 'produce', 'a', 'coherent', 'summary', ',', 'will', 'but', 'weak', 'in', 'term', 'of', 'simplifying', 'complex', 'and', 'long', 'sentence', '.'], ['In', 'contrast', 'to', 'extractive', 'summarization', ',', 'sentence', 'generated', 'by', 'abstractive', 'summary', 'are', 'new', 'sentence', 'or', 'commonly', 'called', 'paraphrase', 'which', 'produce', 'summary', 'using', 'word', 'that', 'are', 'not', 'in', 'the', 'text', '.'], ['Abstractive', 'summary', 'are', 'very', 'complex', 'and', 'relatively', 'more', 'difficult', 'than', 'extractive', 'summary', 'because', 'producing', 'abstractive', 'summary', 'requires', 'extensive', 'natural', 'language', 'processing', '(', 'Gambhir', 'and', 'Gupta', ',', '2017', ')', '.'], ['Approach', 'technique', 'in', 'abstractive', 'summary', 'are', 'generally', 'grouped', 'into', 'two', 'category', 'namely', 'the', 'linguistic', 'approach', 'and', 'the', 'semantic', 'approach', '.'], ['Examples', 'of', 'method', 'that', 'use', 'linguistic', 'approach', 'such', 'a', 'information-based', 'method', '(', 'Genest', 'and', 'Lapalme', ',', '2012', ')', 'and', 'tree-based', 'method', '(', 'Barzilay', 'et', 'al.', ',', '1999', ',', 'Tanaka', 'et', 'al.', ',', '2009', ')', '.'], ['While', 'example', 'of', 'method', 'that', 'use', 'semantic', 'approach', 'such', 'a', 'template-based', 'method', '(', 'Genest', 'and', 'Lapalme', ',', '2011', ')', 'and', 'ontology-based', 'method', '(', 'Chang-Shing', 'et', 'al.', ',', '2005', ')', '.'], ['More', 'recently', 'research', 'on', 'abstractive', 'summarizing', 'ha', 'been', 'inspired', 'by', 'the', 'encoder-decoder', 'framework', ',', 'a', 'in', 'research', 'conducted', 'by', 'Xu', 'et', 'al', '.'], ['(', '2020', ')', ';', 'Lee', 'et', 'al', '.'], ['(', '2020', ')', ';', 'Yao', 'et', 'al', '.'], ['(', '2018a', ')', ';', 'Iwasaki', 'et', 'al', '.'], ['(', '2019', ')', '.'], ['Besides', 'being', 'believed', 'that', 'this', 'model', 'is', 'smoother', ',', 'the', 'encoder-decoder', 'framework', 'is', 'also', 'convenient', 'in', 'adjusting', 'parameter', 'automatically', '(', 'Xu', 'et', 'al.', ',', '2020', ')', '.'], ['In', 'the', '2000s', ',', 'there', 'be', 'a', 'renewed', 'trend', 'in', 'the', 'field', 'of', 'text', 'summarizing', 'research', '.'], ['Summaries', 'are', 'not', 'only', 'generated', 'once', 'but', 'are', 'also', 'able', 'to', 'summarize', 'event', 'in', 'real-time', 'or', 'update', 'summary', 'when', 'new', 'information', 'appears', 'called', 'real-time', 'summarization', '(', 'Ekstrand-abueg', 'et', 'al.', ',', '2016', ',', 'Lou', 'and', 'Man', ',', '2012', ',', 'H', ',', 'A.S.S.', ',', 'K', ',', 'M.M.C.', ',', ',', '2016', ',', 'Maio', 'et', 'al.', ',', '2015', ',', 'Rodríguez-Vidal', 'et', 'al.', ',', '2019', ',', 'Kacprzyk', 'et', 'al.', ',', '2008', ',', 'Fu', 'et', 'al.', ',', '2015', ',', 'Wu', 'et', 'al.', ',', '2015a', ',', 'Wu', 'et', 'al.', ',', '2015b', ',', 'Wang', 'et', 'al.', ',', '2014', ')', '.'], ['Approach', 'technique', 'that', 'have', 'been', 'used', 'in', 'real-time', 'summarization', 'are', 'fuzzy-based', 'and', 'machine', 'learning', '.'], ['An', 'example', 'of', 'a', 'method', 'that', 'us', 'a', 'fuzzy-based', 'approach', 'is', 'the', 'fuzzy', 'logic', 'with', 'classic', 'Zadeh', \"'s\", 'calculus', 'of', 'linguistically', 'quantified', 'proposition', '(', 'Kacprzyk', 'et', 'al.', ',', '2008', ')', 'which', 'address', 'trend', 'extraction', 'and', 'real-time', 'problem', 'where', 'the', 'result', 'are', 'superior', 'in', 't-norm', 'evaluation', ',', 'but', 'weak', 'in', 'semantic', 'problem', 'because', 'the', 'semantic', 'result', 'of', 'other', 't-norms', 'are', 'unclear', 'and', 'unclear', 'can', 'be', 'understood', '.'], ['Fuzzy', 'Formal', 'Concept', 'Analysis', '(', 'Fuzzy', 'FCA', ')', '(', 'Maio', 'et', 'al.', ',', '2015', ')', 'which', 'address', 'semantic', 'and', 'real', 'time', 'problem', 'where', 'the', 'result', 'excel', 'at', 'evaluation', 'in', 'f-measures', 'with', 'optimal', 'recall', 'and', 'comparable', 'precision', '.'], ['An', 'example', 'of', 'a', 'method', 'that', 'us', 'a', 'machine', 'learning', 'approach', 'is', 'Incremental', 'Short', 'Text', 'Summarization', '(', 'IncreSTS', ')', 'by', 'Liu', 'et', 'al.', ',', '2015a', ',', 'Liu', 'et', 'al.', ',', '2015b', 'which', 'ha', 'better', 'outlier', 'handling', ',', 'high', 'efficiency', ',', 'and', 'scalability', 'on', 'target', 'problem', '.'], ['Rank-biased', 'precision-summarization', '(', 'RBP-SUM', ')', 'by', 'Rodríguez-Vidal', 'et', 'al', '.'], ['(', '2019', ')', 'which', 'ha', 'advantage', 'in', 'overcoming', 'redundancy', 'by', 'evaluating', 'using', 'rouge', ',', 'but', 'this', 'method', 'can', 'only', 'produce', 'extractive', 'summary', '.'], ['Text', 'summarization', 'is', 'a', 'formidable', 'challenge', 'in', 'the', 'field', 'of', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', '(', 'Rane', 'and', 'Govilkar', ',', '2019', ',', 'Shabbir', 'Moiyadi', 'et', 'al.', ',', '2016', ')', 'because', 'it', 'requires', 'precise', 'text', 'analysis', 'such', 'a', 'semantic', 'analysis', 'and', 'lexical', 'analysis', 'to', 'produce', 'a', 'good', 'summary', '.'], ['A', 'good', 'summary', ',', 'in', 'addition', ',', 'must', 'contain', 'important', 'information', 'and', 'must', 'be', 'concise', 'but', 'also', 'must', 'consider', 'aspect', 'such', 'a', 'non-redundancy', ',', 'relevance', ',', 'coverage', ',', 'coherence', ',', 'and', 'readability', '(', 'Verma', 'et', 'al.', ',', '2019', ')', '.'], ['Where', 'to', 'get', 'all', 'these', 'aspect', 'in', 'a', 'summary', 'is', 'a', 'great', 'challenge', '.'], ['The', 'review', 'of', 'paper', 'on', 'text', 'summarization', 'is', 'important', 'because', 'summarizing', 'extractive', 'technique', 'ha', 'become', 'a', 'very', 'broad', 'research', 'topic', 'and', 'is', 'heading', 'towards', 'maturity', '(', 'Gupta', 'and', 'Gupta', ',', '2019', ')', '.'], ['Now', 'research', 'ha', 'shifted', 'towards', 'abstractive', 'summarization', '(', 'Gupta', 'and', 'Gupta', ',', '2019', ')', 'and', 'real-time', 'summarization', '.'], ['This', 'is', 'because', 'abstractive', 'summary', 'are', 'more', 'complex', 'and', 'complicated', 'than', 'extractive', 'summary', '.'], ['So', 'extractive', 'summary', 'are', 'easier', 'to', 'give', 'expected', 'and', 'better', 'result', 'than', 'abstractive', 'summary', '(', 'Elrefaiy', 'et', 'al.', ',', '2018', ',', 'Allahyari', 'et', 'al.', ',', '2017', ',', 'Mishra', 'and', 'Gayen', ',', '2018', ')', '.'], ['However', ',', 'extractive', 'summarization', 'is', 'also', 'still', 'in', 'great', 'demand', 'a', 'evident', 'extractive', 'research', 'still', 'exists', 'in', 'the', 'last', 'two', 'year', '(', 'Ren', 'et', 'al.', ',', '2018', ',', 'Sanchez-gomez', 'et', 'al.', ',', '2018', ',', 'Yao', 'et', 'al.', ',', '2018b', ',', 'Khan', 'et', 'al.', ',', '2019', ',', 'Qaroush', 'et', 'al.', ',', '2019', ',', 'Anand', 'and', 'Wagh', ',', '2019', ',', 'Lierde', 'and', 'Chow', ',', '2019', ')', '.'], ['This', 'indicates', 'the', 'possibility', 'that', 'there', 'are', 'still', 'opportunity', 'or', 'loophole', 'to', 'improve', '.'], ['A', 'clear', 'literature', 'study', 'is', 'demanded', 'a', 'a', 'mean', 'for', 'the', 'advancement', 'of', 'research', 'in', 'the', 'field', 'of', 'text', 'summarization', '.'], ['Where', 'literature', 'study', 'are', 'generally', 'contained', ',', 'analyzed', ',', 'and', 'compared', 'in', 'a', 'review', 'or', 'survey', 'paper', '.'], ['Review', 'paper', 'made', 'by', 'Gupta', 'and', 'Gupta', '(', '2019', ')', 'discus', 'popular', 'component', 'specifically', 'about', 'abstractive', 'summarizing', ',', 'such', 'a', 'research', 'trend', 'in', 'the', 'field', 'of', 'abstractive', 'summarization', ',', 'general', 'description', 'of', 'existing', 'abstractive', 'summarizing', 'technique', ',', 'tool', ',', 'and', 'evaluation', '.'], ['Other', 'review', 'were', 'conducted', 'by', 'Abualigah', 'et', 'al', '.'], ['(', '2020', ')', 'gave', 'a', 'brief', 'survey', 'of', 'the', 'technique', 'of', 'text', 'summarization', 'and', 'specifically', 'in', 'Arabic', '.'], ['A', 'survey', 'conducted', 'by', 'Nazari', 'and', 'Mahdavi', '(', '2018', ')', 'discussing', 'text', 'summarization', 'focus', 'on', 'the', 'approach', 'technique', 'and', 'method', 'used', 'in', 'text', 'summarization', '.'], ['Nazari', 'and', 'Mahdavi', '(', '2018', ')', 'grouped', 'approach', 'to', 'statistic', ',', 'machine', 'learning', ',', 'semantic-based', ',', 'and', 'swarm', 'intelligence', '.'], ['Another', 'survey', 'be', 'conducted', 'by', 'Elrefaiy', 'et', 'al', '.'], ['(', '2018', ')', 'which', 'is', 'about', 'summarizing', 'extractive', 'text', 'that', 'focus', 'on', 'unattended', 'technique', ',', 'present', 'a', 'list', 'of', 'strength', 'and', 'weakness', 'in', 'a', 'comparison', 'table', ',', 'alluding', 'to', 'a', 'little', 'about', 'evaluation', 'and', 'future', 'trend', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Stop Words Removal"
      ],
      "metadata": {
        "id": "uKHrgo0Et4h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords=s.Defaults.stop_words\n",
        "for idx,sent in enumerate(words):\n",
        "  temp=[]\n",
        "  for word in sent:\n",
        "    if(word not in stopwords):\n",
        "      temp.append(word)\n",
        "  words[idx] = temp\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ltVYqFFt32l",
        "outputId": "76c1f976-4745-4522-8268-e73c59f1556e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Along', 'growth', 'internet', 'big', 'data', ',', 'making', 'people', 'overwhelmed', 'large', 'information', 'document', 'internet', '.'], ['This', 'trigger', 'desire', 'researcher', 'develop', 'technological', 'approach', 'summarize', 'text', 'automatically', '.'], ['Automatic', 'text', 'summarization', 'generates', 'summary', 'containing', 'important', 'sentence', 'includes', 'important', 'relevant', 'information', 'original', 'document', '(', 'Allahyari', 'et', 'al.', ',', '2017', ',', 'Gambhir', 'Gupta', ',', '2017', ')', '.'], ['So', 'information', 'quickly', 'arrives', 'doe', 'lose', 'original', 'intent', 'document', '(', 'Murad', 'Martin', ',', '2007', ')', '.'], ['The', 'area', 'text', 'summarization', 'research', 'ha', 'studied', 'mid-20th', 'century', ',', 'discussed', 'openly', 'Lun', '(', '1958', ')', 'statistical', 'technique', 'word', 'frequency', 'diagram', '.'], ['Many', 'different', 'approach', 'created', 'date', '.'], ['Based', 'number', 'document', ',', 'single', 'multi-document', 'summarization', '.'], ['Meanwhile', ',', 'based', 'summary', 'result', 'extractive', 'abstractive', 'result', '.'], ['A', 'single', 'document', 'produce', 'summary', 'sourced', 'source', 'document', '(', 'Radev', 'et', 'al.', ',', '2001', ')', 'content', 'described', 'topic', '.'], ['While', 'multi-document', 'summarization', 'taken', 'source', 'document', 'discus', 'topic', '(', 'Qiang', 'et', 'al.', ',', '2016', ',', 'Ansamma', 'et', 'al.', ',', '2017', ',', 'Widjanarko', 'et', 'al.', ',', '2018', ')', '.'], ['(', 'Christian', 'et', 'al.', ',', '2016', ')', 'text', 'summarizing', 'single', 'document', 'TF-IDF', '(', 'Sarkar', ',', '2013', ')', 'designed', 'automatic', 'text', 'summarizing', 'single', 'document', 'Main', 'Concepts', '.'], ['(', 'Qiang', 'et', 'al.', ',', '2016', ')', 'summarized', 'multiple', 'document', 'pattern-based', 'summarization', '(', 'Patsum', ')', 'method', '2004', 'DUC', 'dataset', 'showed', 'result', 'outperformed', 'term-based', 'method', 'ontology-based', 'method', '.'], ['Ansamma', 'et', 'al', '.'], ['(', '2017', ')', 'summarized', 'multiple', 'document', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'Non-Negative', 'Matrix', 'Factorization', '(', 'NMF', ')', 'result', 'outperformed', 'state', 'art', 'precision', 'recall', '.'], ['Qaroush', 'et', 'al', '.'], ['(', '2019', ')', 'proposes', 'summarization', 'Arabic', 'single', 'document', 'produce', 'fairly', 'informative', 'extractive', 'summary', 'combining', 'machine', 'learning', 'score-based', 'approach', 'evaluate', 'sentence', 'based', 'combination', 'semantics', 'statistic', '.'], ['The', 'result', 'superior', 'term', 'precision', 'metric', ',', 'memory', ',', 'F-scores', ',', 'disadvantage', 'ha', 'optimized', 'weight', 'feature', '.'], ['Verma', 'Om', '(', '2019', ')', 'minimized', 'redundancy', 'multi-document', 'summarizing', 'Shark', 'Smell', 'Optimization', '(', 'SSO', ')', 'method', 'performance', 'result', 'far', 'better', 'previous', 'summary', 'method', '.'], ['Extractive', 'summarization', 'summary', 'summary', 'consist', 'entirely', 'extracted', 'content', 'result', 'summary', 'sentence', 'sentence', 'word', 'obtained', 'original', 'text', '(', 'Khan', 'Salim', ',', '2014', ')', '.'], ['The', 'usual', 'problem', 'raised', 'extractive', 'summarization', 'research', 'determining', 'position', 'sentence', '(', 'Khan', 'Salim', ',', '2014', ')', 'frequency', 'word', 'text', '(', 'Baxendale', ',', '1958', ')', '.'], ['The', 'experiment', 'raised', 'extraction', 'problem', 'known', 'Information', 'Extraction', '(', 'IE', ')', 'technique', 'produce', 'summary', 'specific', 'result', 'increase', 'accuracy', '.'], ['One', 'example', 'automatic', 'summarizing', 'system', 'ha', 'developed', 'adopting', 'IE', 'technique', 'RIPTIDES', ',', 'function', 'summarize', 'news', 'based', 'scenario', 'chosen', 'user', '(', 'White', 'et', 'al.', ',', '2001', ')', '.'], ['Research', 'Naik', 'Gaonkar', '(', '2017', ')', 'rule', 'base', 'produce', 'best', 'average', 'precision', ',', 'f-measure', ',', 'recall', 'value', 'Rule-Based', 'Summarizers', 'ha', 'tried', 'broader', 'data', '.'], ['Furthermore', ',', 'extractive', 'summarizing', 'study', 'neural', 'network', ',', 'recent', 'year', 'achieved', 'greater', 'popularity', 'conventional', 'approach', ',', 'study', '(', 'Mohsen', 'et', 'al.', ',', '2020', ',', 'Anand', 'Wagh', ',', '2019', ',', 'Xu', 'Durrett', ',', '2019', ',', 'Chen', 'et', 'al.', ',', '2018a', ',', 'Chen', 'et', 'al.', ',', '2018b', ',', 'Alami', 'et', 'al.', ',', '2019', ')', '.'], ['Research', 'conducted', 'Anand', 'Wagh', '(', '2019', ')', 'deep', 'learning', 'technique', 'Feed', 'Forward', 'Neural', 'Network', '(', 'FFNN', ')', 'summarize', 'single', 'document', 'legal', 'document', 'ha', 'advantage', 'producing', 'extractive', 'summary', 'need', 'create', 'feature', 'domain', 'knowledge', 'perform', 'measured', 'Rouge', 'score', 'produce', 'coherent', 'summary', ',', 'weak', 'term', 'simplifying', 'complex', 'long', 'sentence', '.'], ['In', 'contrast', 'extractive', 'summarization', ',', 'sentence', 'generated', 'abstractive', 'summary', 'new', 'sentence', 'commonly', 'called', 'paraphrase', 'produce', 'summary', 'word', 'text', '.'], ['Abstractive', 'summary', 'complex', 'relatively', 'difficult', 'extractive', 'summary', 'producing', 'abstractive', 'summary', 'requires', 'extensive', 'natural', 'language', 'processing', '(', 'Gambhir', 'Gupta', ',', '2017', ')', '.'], ['Approach', 'technique', 'abstractive', 'summary', 'generally', 'grouped', 'category', 'linguistic', 'approach', 'semantic', 'approach', '.'], ['Examples', 'method', 'use', 'linguistic', 'approach', 'information-based', 'method', '(', 'Genest', 'Lapalme', ',', '2012', ')', 'tree-based', 'method', '(', 'Barzilay', 'et', 'al.', ',', '1999', ',', 'Tanaka', 'et', 'al.', ',', '2009', ')', '.'], ['While', 'example', 'method', 'use', 'semantic', 'approach', 'template-based', 'method', '(', 'Genest', 'Lapalme', ',', '2011', ')', 'ontology-based', 'method', '(', 'Chang-Shing', 'et', 'al.', ',', '2005', ')', '.'], ['More', 'recently', 'research', 'abstractive', 'summarizing', 'ha', 'inspired', 'encoder-decoder', 'framework', ',', 'research', 'conducted', 'Xu', 'et', 'al', '.'], ['(', '2020', ')', ';', 'Lee', 'et', 'al', '.'], ['(', '2020', ')', ';', 'Yao', 'et', 'al', '.'], ['(', '2018a', ')', ';', 'Iwasaki', 'et', 'al', '.'], ['(', '2019', ')', '.'], ['Besides', 'believed', 'model', 'smoother', ',', 'encoder-decoder', 'framework', 'convenient', 'adjusting', 'parameter', 'automatically', '(', 'Xu', 'et', 'al.', ',', '2020', ')', '.'], ['In', '2000s', ',', 'renewed', 'trend', 'field', 'text', 'summarizing', 'research', '.'], ['Summaries', 'generated', 'able', 'summarize', 'event', 'real-time', 'update', 'summary', 'new', 'information', 'appears', 'called', 'real-time', 'summarization', '(', 'Ekstrand-abueg', 'et', 'al.', ',', '2016', ',', 'Lou', 'Man', ',', '2012', ',', 'H', ',', 'A.S.S.', ',', 'K', ',', 'M.M.C.', ',', ',', '2016', ',', 'Maio', 'et', 'al.', ',', '2015', ',', 'Rodríguez-Vidal', 'et', 'al.', ',', '2019', ',', 'Kacprzyk', 'et', 'al.', ',', '2008', ',', 'Fu', 'et', 'al.', ',', '2015', ',', 'Wu', 'et', 'al.', ',', '2015a', ',', 'Wu', 'et', 'al.', ',', '2015b', ',', 'Wang', 'et', 'al.', ',', '2014', ')', '.'], ['Approach', 'technique', 'real-time', 'summarization', 'fuzzy-based', 'machine', 'learning', '.'], ['An', 'example', 'method', 'fuzzy-based', 'approach', 'fuzzy', 'logic', 'classic', 'Zadeh', 'calculus', 'linguistically', 'quantified', 'proposition', '(', 'Kacprzyk', 'et', 'al.', ',', '2008', ')', 'address', 'trend', 'extraction', 'real-time', 'problem', 'result', 'superior', 't-norm', 'evaluation', ',', 'weak', 'semantic', 'problem', 'semantic', 'result', 't-norms', 'unclear', 'unclear', 'understood', '.'], ['Fuzzy', 'Formal', 'Concept', 'Analysis', '(', 'Fuzzy', 'FCA', ')', '(', 'Maio', 'et', 'al.', ',', '2015', ')', 'address', 'semantic', 'real', 'time', 'problem', 'result', 'excel', 'evaluation', 'f-measures', 'optimal', 'recall', 'comparable', 'precision', '.'], ['An', 'example', 'method', 'machine', 'learning', 'approach', 'Incremental', 'Short', 'Text', 'Summarization', '(', 'IncreSTS', ')', 'Liu', 'et', 'al.', ',', '2015a', ',', 'Liu', 'et', 'al.', ',', '2015b', 'ha', 'better', 'outlier', 'handling', ',', 'high', 'efficiency', ',', 'scalability', 'target', 'problem', '.'], ['Rank-biased', 'precision-summarization', '(', 'RBP-SUM', ')', 'Rodríguez-Vidal', 'et', 'al', '.'], ['(', '2019', ')', 'ha', 'advantage', 'overcoming', 'redundancy', 'evaluating', 'rouge', ',', 'method', 'produce', 'extractive', 'summary', '.'], ['Text', 'summarization', 'formidable', 'challenge', 'field', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', '(', 'Rane', 'Govilkar', ',', '2019', ',', 'Shabbir', 'Moiyadi', 'et', 'al.', ',', '2016', ')', 'requires', 'precise', 'text', 'analysis', 'semantic', 'analysis', 'lexical', 'analysis', 'produce', 'good', 'summary', '.'], ['A', 'good', 'summary', ',', 'addition', ',', 'contain', 'important', 'information', 'concise', 'consider', 'aspect', 'non-redundancy', ',', 'relevance', ',', 'coverage', ',', 'coherence', ',', 'readability', '(', 'Verma', 'et', 'al.', ',', '2019', ')', '.'], ['Where', 'aspect', 'summary', 'great', 'challenge', '.'], ['The', 'review', 'paper', 'text', 'summarization', 'important', 'summarizing', 'extractive', 'technique', 'ha', 'broad', 'research', 'topic', 'heading', 'maturity', '(', 'Gupta', 'Gupta', ',', '2019', ')', '.'], ['Now', 'research', 'ha', 'shifted', 'abstractive', 'summarization', '(', 'Gupta', 'Gupta', ',', '2019', ')', 'real-time', 'summarization', '.'], ['This', 'abstractive', 'summary', 'complex', 'complicated', 'extractive', 'summary', '.'], ['So', 'extractive', 'summary', 'easier', 'expected', 'better', 'result', 'abstractive', 'summary', '(', 'Elrefaiy', 'et', 'al.', ',', '2018', ',', 'Allahyari', 'et', 'al.', ',', '2017', ',', 'Mishra', 'Gayen', ',', '2018', ')', '.'], ['However', ',', 'extractive', 'summarization', 'great', 'demand', 'evident', 'extractive', 'research', 'exists', 'year', '(', 'Ren', 'et', 'al.', ',', '2018', ',', 'Sanchez-gomez', 'et', 'al.', ',', '2018', ',', 'Yao', 'et', 'al.', ',', '2018b', ',', 'Khan', 'et', 'al.', ',', '2019', ',', 'Qaroush', 'et', 'al.', ',', '2019', ',', 'Anand', 'Wagh', ',', '2019', ',', 'Lierde', 'Chow', ',', '2019', ')', '.'], ['This', 'indicates', 'possibility', 'opportunity', 'loophole', 'improve', '.'], ['A', 'clear', 'literature', 'study', 'demanded', 'mean', 'advancement', 'research', 'field', 'text', 'summarization', '.'], ['Where', 'literature', 'study', 'generally', 'contained', ',', 'analyzed', ',', 'compared', 'review', 'survey', 'paper', '.'], ['Review', 'paper', 'Gupta', 'Gupta', '(', '2019', ')', 'discus', 'popular', 'component', 'specifically', 'abstractive', 'summarizing', ',', 'research', 'trend', 'field', 'abstractive', 'summarization', ',', 'general', 'description', 'existing', 'abstractive', 'summarizing', 'technique', ',', 'tool', ',', 'evaluation', '.'], ['Other', 'review', 'conducted', 'Abualigah', 'et', 'al', '.'], ['(', '2020', ')', 'gave', 'brief', 'survey', 'technique', 'text', 'summarization', 'specifically', 'Arabic', '.'], ['A', 'survey', 'conducted', 'Nazari', 'Mahdavi', '(', '2018', ')', 'discussing', 'text', 'summarization', 'focus', 'approach', 'technique', 'method', 'text', 'summarization', '.'], ['Nazari', 'Mahdavi', '(', '2018', ')', 'grouped', 'approach', 'statistic', ',', 'machine', 'learning', ',', 'semantic-based', ',', 'swarm', 'intelligence', '.'], ['Another', 'survey', 'conducted', 'Elrefaiy', 'et', 'al', '.'], ['(', '2018', ')', 'summarizing', 'extractive', 'text', 'focus', 'unattended', 'technique', ',', 'present', 'list', 'strength', 'weakness', 'comparison', 'table', ',', 'alluding', 'little', 'evaluation', 'future', 'trend', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Named Entities"
      ],
      "metadata": {
        "id": "84d_876wOwQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "named_entities=[]\n",
        "for i in tagged_words:\n",
        "  named_entities.append(nltk.ne_chunk(i))"
      ],
      "metadata": {
        "id": "1J-qq_iWqhpt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using nltk\n",
        "named_entities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_mJEIvV0MpP",
        "outputId": "a692ee52-747a-4b01-b71d-f07171b0ad08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tree('S', [('Along', 'IN'), ('with', 'IN'), ('the', 'DT'), ('growth', 'NN'), ('of', 'IN'), ('the', 'DT'), ('internet', 'NN'), ('and', 'CC'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('making', 'VBG'), ('people', 'NNS'), ('overwhelmed', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('large', 'JJ'), ('information', 'NN'), ('and', 'CC'), ('documents', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('internet', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('This', 'DT'), ('triggers', 'VBZ'), ('the', 'DT'), ('desire', 'NN'), ('of', 'IN'), ('many', 'JJ'), ('researchers', 'NNS'), ('to', 'TO'), ('develop', 'VB'), ('a', 'DT'), ('technological', 'JJ'), ('approach', 'NN'), ('that', 'WDT'), ('can', 'MD'), ('summarize', 'VB'), ('texts', 'JJ'), ('automatically', 'RB'), ('.', '.')]),\n",
              " Tree('S', [Tree('GPE', [('Automatic', 'NNP')]), ('text', 'NN'), ('summarization', 'NN'), ('generates', 'VBZ'), ('summaries', 'NNS'), ('containing', 'VBG'), ('important', 'JJ'), ('sentences', 'NNS'), ('and', 'CC'), ('includes', 'VBZ'), ('all', 'DT'), ('important', 'JJ'), ('relevant', 'JJ'), ('information', 'NN'), ('from', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('document', 'NN'), ('(', '('), Tree('PERSON', [('Allahyari', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2017', 'CD'), (',', ','), Tree('PERSON', [('Gambhir', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Gupta', 'NNP')]), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('So', 'RB'), ('the', 'DT'), ('information', 'NN'), ('quickly', 'RB'), ('arrives', 'VBZ'), ('and', 'CC'), ('does', 'VBZ'), ('not', 'RB'), ('lose', 'VB'), ('the', 'DT'), ('original', 'JJ'), ('intent', 'NN'), ('of', 'IN'), ('the', 'DT'), ('document', 'NN'), ('(', '('), Tree('PERSON', [('Murad', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Martin', 'NNP')]), (',', ','), ('2007', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('The', 'DT'), ('area', 'NN'), ('of', 'IN'), ('text', 'JJ'), ('summarization', 'NN'), ('research', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('studied', 'VBN'), ('since', 'IN'), ('the', 'DT'), ('mid-20th', 'JJ'), ('century', 'NN'), (',', ','), ('which', 'WDT'), ('was', 'VBD'), ('first', 'RB'), ('discussed', 'VBN'), ('openly', 'RB'), ('by', 'IN'), Tree('GPE', [('Lun', 'NNP')]), ('(', '('), ('1958', 'CD'), (')', ')'), ('with', 'IN'), ('a', 'DT'), ('statistical', 'JJ'), ('technique', 'NN'), ('namely', 'RB'), ('word', 'NN'), ('frequency', 'NN'), ('diagrams', 'NNS'), ('.', '.')]),\n",
              " Tree('S', [('Many', 'JJ'), ('different', 'JJ'), ('approaches', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('created', 'VBN'), ('to', 'TO'), ('date', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('Based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('the', 'DT'), ('document', 'NN'), (',', ','), ('there', 'EX'), ('is', 'VBZ'), ('single', 'JJ'), ('and', 'CC'), ('multi-document', 'JJ'), ('summarization', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('Meanwhile', 'RB'), (',', ','), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('summary', 'JJ'), ('results', 'NNS'), ('there', 'EX'), ('are', 'VBP'), ('the', 'DT'), ('extractive', 'JJ'), ('and', 'CC'), ('abstractive', 'JJ'), ('results', 'NNS'), ('.', '.')]),\n",
              " Tree('S', [('A', 'DT'), ('single', 'JJ'), ('document', 'NN'), ('produces', 'VBZ'), ('a', 'DT'), ('summary', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('sourced', 'VBN'), ('from', 'IN'), ('one', 'CD'), ('source', 'NN'), ('document', 'NN'), ('(', '('), Tree('PERSON', [('Radev', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2001', 'CD'), (')', ')'), ('and', 'CC'), ('the', 'DT'), ('content', 'NN'), ('described', 'NN'), ('is', 'VBZ'), ('around', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('topic', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('While', 'IN'), ('the', 'DT'), ('multi-document', 'JJ'), ('summarization', 'NN'), ('is', 'VBZ'), ('taken', 'VBN'), ('from', 'IN'), ('various', 'JJ'), ('sources', 'NNS'), ('or', 'CC'), ('documents', 'NNS'), ('that', 'WDT'), ('discuss', 'VBP'), ('the', 'DT'), ('same', 'JJ'), ('topic', 'NN'), ('(', '('), Tree('PERSON', [('Qiang', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (',', ','), Tree('PERSON', [('Ansamma', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2017', 'CD'), (',', ','), Tree('PERSON', [('Widjanarko', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('(', '('), Tree('GPE', [('Christian', 'JJ')]), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('made', 'VBD'), ('text', 'JJ'), ('summarizing', 'NN'), ('in', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('document', 'NN'), ('using', 'VBG'), ('TF-IDF', 'NNP'), ('and', 'CC'), ('(', '('), Tree('PERSON', [('Sarkar', 'NNP')]), (',', ','), ('2013', 'CD'), (')', ')'), ('designed', 'VBN'), ('automatic', 'JJ'), ('text', 'NN'), ('summarizing', 'NN'), ('in', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('document', 'NN'), ('using', 'VBG'), ('the', 'DT'), Tree('ORGANIZATION', [('Main', 'NNP'), ('Concepts', 'NNP')]), ('.', '.')]),\n",
              " Tree('S', [('(', '('), Tree('PERSON', [('Qiang', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('summarized', 'VBD'), ('multiple', 'JJ'), ('documents', 'NNS'), ('by', 'IN'), ('the', 'DT'), ('pattern-based', 'JJ'), ('summarization', 'NN'), ('(', '('), Tree('PERSON', [('Patsum', 'NNP')]), (')', ')'), ('method', 'NN'), ('on', 'IN'), ('the', 'DT'), ('2004', 'CD'), ('DUC', 'NNP'), ('dataset', 'NN'), ('and', 'CC'), ('showed', 'VBD'), ('that', 'IN'), ('the', 'DT'), ('results', 'NNS'), ('outperformed', 'VBD'), ('not', 'RB'), ('only', 'RB'), ('the', 'DT'), ('term-based', 'JJ'), ('method', 'NN'), ('but', 'CC'), ('also', 'RB'), ('the', 'DT'), ('ontology-based', 'JJ'), ('method', 'NN'), ('.', '.')]),\n",
              " Tree('S', [Tree('GPE', [('Ansamma', 'NNP')]), ('et', 'CC'), ('al', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('(', '('), ('2017', 'CD'), (')', ')'), ('summarized', 'VBD'), ('multiple', 'JJ'), ('documents', 'NNS'), ('using', 'VBG'), Tree('PERSON', [('Latent', 'NNP'), ('Semantic', 'NNP'), ('Analysis', 'NNP')]), ('(', '('), Tree('ORGANIZATION', [('LSA', 'NNP')]), (')', ')'), ('and', 'CC'), ('Non-Negative', 'JJ'), Tree('PERSON', [('Matrix', 'NNP'), ('Factorization', 'NNP')]), ('(', '('), Tree('ORGANIZATION', [('NMF', 'NNP')]), (')', ')'), ('and', 'CC'), ('the', 'DT'), ('results', 'NNS'), ('outperformed', 'VBD'), ('the', 'DT'), ('state', 'NN'), ('of', 'IN'), ('the', 'DT'), ('art', 'NN'), ('in', 'IN'), ('precision', 'NN'), ('and', 'CC'), ('recall', 'NN'), ('.', '.')]),\n",
              " Tree('S', [Tree('GPE', [('Qaroush', 'NNP')]), ('et', 'CC'), ('al', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('(', '('), ('2019', 'CD'), (')', ')'), ('proposes', 'VBZ'), ('the', 'DT'), ('summarization', 'NN'), ('of', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('Arabic', 'NNP')]), ('single', 'JJ'), ('document', 'NN'), ('which', 'WDT'), ('produces', 'VBZ'), ('a', 'DT'), ('fairly', 'RB'), ('informative', 'JJ'), ('extractive', 'JJ'), ('summary', 'JJ'), ('combining', 'NN'), ('machine', 'NN'), ('learning', 'NN'), ('and', 'CC'), ('score-based', 'JJ'), ('approaches', 'NNS'), ('that', 'WDT'), ('evaluate', 'VBP'), ('each', 'DT'), ('sentence', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('a', 'DT'), ('combination', 'NN'), ('of', 'IN'), ('semantics', 'NNS'), ('and', 'CC'), ('statistics', 'NNS'), ('.', '.')]),\n",
              " Tree('S', [('The', 'DT'), ('results', 'NNS'), ('are', 'VBP'), ('superior', 'JJ'), ('in', 'IN'), ('terms', 'NNS'), ('of', 'IN'), ('precision', 'NN'), ('metrics', 'NNS'), (',', ','), ('memory', 'NN'), (',', ','), ('and', 'CC'), ('F-scores', 'NNS'), (',', ','), ('the', 'DT'), ('disadvantage', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('it', 'PRP'), ('has', 'VBZ'), ('not', 'RB'), ('optimized', 'VBN'), ('the', 'DT'), ('weight', 'NN'), ('of', 'IN'), ('the', 'DT'), ('features', 'NNS'), ('.', '.')]),\n",
              " Tree('S', [Tree('GPE', [('Verma', 'NNP')]), ('and', 'CC'), Tree('GPE', [('Om', 'NNP')]), ('(', '('), ('2019', 'CD'), (')', ')'), ('minimized', 'VBN'), ('redundancy', 'NN'), ('in', 'IN'), ('multi-document', 'JJ'), ('summarizing', 'NN'), ('by', 'IN'), ('the', 'DT'), Tree('PERSON', [('Shark', 'NNP'), ('Smell', 'NNP')]), ('Optimization', 'NNP'), ('(', '('), Tree('ORGANIZATION', [('SSO', 'NNP')]), (')', ')'), ('method', 'NN'), ('and', 'CC'), ('the', 'DT'), ('performance', 'NN'), ('results', 'NNS'), ('were', 'VBD'), ('far', 'RB'), ('better', 'JJR'), ('than', 'IN'), ('the', 'DT'), ('previous', 'JJ'), ('summary', 'JJ'), ('method', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('Extractive', 'JJ'), ('summarization', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('summary', 'JJ'), ('that', 'WDT'), ('summaries', 'VBZ'), ('consist', 'VBP'), ('entirely', 'RB'), ('of', 'IN'), ('extracted', 'JJ'), ('content', 'NN'), ('so', 'IN'), ('that', 'IN'), ('the', 'DT'), ('results', 'NNS'), ('of', 'IN'), ('summary', 'JJ'), ('sentences', 'NNS'), ('are', 'VBP'), ('sentences', 'NNS'), ('or', 'CC'), ('words', 'NNS'), ('obtained', 'VBN'), ('from', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('text', 'NN'), ('(', '('), Tree('ORGANIZATION', [('Khan', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Salim', 'NNP')]), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('The', 'DT'), ('usual', 'JJ'), ('problem', 'NN'), ('raised', 'VBN'), ('from', 'IN'), ('the', 'DT'), ('extractive', 'JJ'), ('summarization', 'NN'), ('research', 'NN'), ('at', 'IN'), ('first', 'JJ'), ('was', 'VBD'), ('determining', 'VBG'), ('the', 'DT'), ('position', 'NN'), ('of', 'IN'), ('the', 'DT'), ('sentence', 'NN'), ('(', '('), Tree('ORGANIZATION', [('Khan', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Salim', 'NNP')]), (',', ','), ('2014', 'CD'), (')', ')'), ('and', 'CC'), ('the', 'DT'), ('frequency', 'NN'), ('of', 'IN'), ('words', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('text', 'NN'), ('(', '('), Tree('ORGANIZATION', [('Baxendale', 'NNP')]), (',', ','), ('1958', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('The', 'DT'), ('next', 'JJ'), ('experiment', 'NN'), ('raised', 'VBD'), ('the', 'DT'), ('extraction', 'NN'), ('problem', 'NN'), ('which', 'WDT'), ('is', 'VBZ'), ('known', 'VBN'), ('as', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('Information', 'NNP'), ('Extraction', 'NNP')]), ('(', '('), ('IE', 'NNP'), (')', ')'), ('technique', 'NN'), ('to', 'TO'), ('produce', 'VB'), ('a', 'DT'), ('summary', 'JJ'), ('with', 'IN'), ('more', 'RBR'), ('specific', 'JJ'), ('results', 'NNS'), ('and', 'CC'), ('to', 'TO'), ('increase', 'VB'), ('accuracy', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('One', 'CD'), ('example', 'NN'), ('of', 'IN'), ('an', 'DT'), ('automatic', 'JJ'), ('summarizing', 'NN'), ('system', 'NN'), ('that', 'WDT'), ('has', 'VBZ'), ('been', 'VBN'), ('developed', 'VBN'), ('by', 'IN'), ('adopting', 'VBG'), ('IE', 'NNP'), ('techniques', 'NNS'), ('is', 'VBZ'), Tree('ORGANIZATION', [('RIPTIDES', 'NNP')]), (',', ','), ('which', 'WDT'), ('functions', 'VBZ'), ('to', 'TO'), ('summarize', 'VB'), ('news', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('scenarios', 'NNS'), ('chosen', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('user', 'NN'), ('(', '('), Tree('FACILITY', [('White', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2001', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('Research', 'NN'), ('by', 'IN'), Tree('PERSON', [('Naik', 'NNP')]), ('and', 'CC'), Tree('GPE', [('Gaonkar', 'NNP')]), ('(', '('), ('2017', 'CD'), (')', ')'), ('using', 'VBG'), ('a', 'DT'), ('rule', 'NN'), ('base', 'NN'), ('produces', 'VBZ'), ('the', 'DT'), ('best', 'JJS'), ('average', 'JJ'), ('precision', 'NN'), (',', ','), ('f-measure', 'NN'), (',', ','), ('and', 'CC'), ('recall', 'VB'), ('values', 'NNS'), ('for', 'IN'), ('Rule-Based', 'JJ'), ('Summarizers', 'NNS'), ('but', 'CC'), ('has', 'VBZ'), ('not', 'RB'), ('yet', 'RB'), ('been', 'VBN'), ('tried', 'VBN'), ('on', 'IN'), ('broader', 'JJR'), ('data', 'NNS'), ('.', '.')]),\n",
              " Tree('S', [('Furthermore', 'RB'), (',', ','), ('there', 'EX'), ('are', 'VBP'), ('extractive', 'JJ'), ('summarizing', 'VBG'), ('studies', 'NNS'), ('using', 'VBG'), ('neural', 'JJ'), ('networks', 'NNS'), (',', ','), ('which', 'WDT'), ('in', 'IN'), ('recent', 'JJ'), ('years', 'NNS'), ('have', 'VBP'), ('achieved', 'VBN'), ('greater', 'JJR'), ('popularity', 'NN'), ('than', 'IN'), ('conventional', 'JJ'), ('approaches', 'NNS'), (',', ','), ('some', 'DT'), ('of', 'IN'), ('these', 'DT'), ('studies', 'NNS'), ('are', 'VBP'), ('(', '('), Tree('PERSON', [('Mohsen', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2020', 'CD'), (',', ','), Tree('GPE', [('Anand', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Wagh', 'NNP')]), (',', ','), ('2019', 'CD'), (',', ','), Tree('PERSON', [('Xu', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Durrett', 'NNP')]), (',', ','), ('2019', 'CD'), (',', ','), Tree('PERSON', [('Chen', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2018a', 'CD'), (',', ','), Tree('PERSON', [('Chen', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2018b', 'CD'), (',', ','), Tree('PERSON', [('Alami', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [Tree('GPE', [('Research', 'NN')]), ('conducted', 'VBN'), ('by', 'IN'), Tree('GPE', [('Anand', 'NNP')]), ('and', 'CC'), Tree('GPE', [('Wagh', 'NNP')]), ('(', '('), ('2019', 'CD'), (')', ')'), ('used', 'VBD'), ('a', 'DT'), ('deep', 'JJ'), ('learning', 'NN'), ('technique', 'NN'), ('namely', 'RB'), Tree('PERSON', [('Feed', 'NNP'), ('Forward', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP')]), ('(', '('), Tree('ORGANIZATION', [('FFNN', 'NNP')]), (')', ')'), ('to', 'TO'), ('summarize', 'VB'), ('a', 'DT'), ('single', 'JJ'), ('document', 'NN'), ('in', 'IN'), ('a', 'DT'), ('legal', 'JJ'), ('document', 'NN'), ('that', 'WDT'), ('has', 'VBZ'), ('the', 'DT'), ('advantage', 'NN'), ('of', 'IN'), ('producing', 'VBG'), ('an', 'DT'), ('extractive', 'JJ'), ('summary', 'NN'), ('without', 'IN'), ('the', 'DT'), ('need', 'NN'), ('to', 'TO'), ('create', 'VB'), ('features', 'NNS'), ('or', 'CC'), ('domain', 'VB'), ('knowledge', 'NN'), ('and', 'CC'), ('perform', 'VB'), ('well', 'RB'), ('as', 'IN'), ('measured', 'VBN'), ('by', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('Rouge', 'NNP')]), ('score', 'NN'), ('and', 'CC'), ('produces', 'VBZ'), ('a', 'DT'), ('coherent', 'NN'), ('summary', 'NN'), (',', ','), ('will', 'MD'), ('but', 'CC'), ('weak', 'JJ'), ('in', 'IN'), ('terms', 'NNS'), ('of', 'IN'), ('simplifying', 'VBG'), ('complex', 'JJ'), ('and', 'CC'), ('long', 'JJ'), ('sentences', 'NNS'), ('.', '.')]),\n",
              " Tree('S', [('In', 'IN'), ('contrast', 'NN'), ('to', 'TO'), ('extractive', 'VB'), ('summarization', 'NN'), (',', ','), ('sentences', 'NNS'), ('generated', 'VBN'), ('by', 'IN'), ('abstractive', 'JJ'), ('summaries', 'NNS'), ('are', 'VBP'), ('new', 'JJ'), ('sentences', 'NNS'), ('or', 'CC'), ('commonly', 'RB'), ('called', 'VBN'), ('paraphrases', 'NNS'), ('which', 'WDT'), ('produce', 'VBP'), ('summaries', 'NNS'), ('using', 'VBG'), ('words', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('not', 'RB'), ('in', 'IN'), ('the', 'DT'), ('text', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('Abstractive', 'JJ'), ('summaries', 'NNS'), ('are', 'VBP'), ('very', 'RB'), ('complex', 'JJ'), ('and', 'CC'), ('relatively', 'RB'), ('more', 'RBR'), ('difficult', 'JJ'), ('than', 'IN'), ('extractive', 'JJ'), ('summaries', 'NNS'), ('because', 'IN'), ('producing', 'VBG'), ('abstractive', 'JJ'), ('summaries', 'NNS'), ('requires', 'VBZ'), ('extensive', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), Tree('ORGANIZATION', [('Gambhir', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Gupta', 'NNP')]), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [Tree('GPE', [('Approach', 'NN')]), ('techniques', 'NNS'), ('in', 'IN'), ('abstractive', 'JJ'), ('summary', 'NN'), ('are', 'VBP'), ('generally', 'RB'), ('grouped', 'VBN'), ('into', 'IN'), ('two', 'CD'), ('categories', 'NNS'), ('namely', 'RB'), ('the', 'DT'), ('linguistic', 'JJ'), ('approach', 'NN'), ('and', 'CC'), ('the', 'DT'), ('semantic', 'JJ'), ('approach', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('Examples', 'NNS'), ('of', 'IN'), ('methods', 'NNS'), ('that', 'WDT'), ('use', 'VBP'), ('linguistic', 'JJ'), ('approaches', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('information-based', 'JJ'), ('methods', 'NNS'), ('(', '('), Tree('ORGANIZATION', [('Genest', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Lapalme', 'NNP')]), (',', ','), ('2012', 'CD'), (')', ')'), ('and', 'CC'), ('tree-based', 'JJ'), ('methods', 'NNS'), ('(', '('), Tree('PERSON', [('Barzilay', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('1999', 'CD'), (',', ','), Tree('PERSON', [('Tanaka', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2009', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('While', 'IN'), ('examples', 'NNS'), ('of', 'IN'), ('methods', 'NNS'), ('that', 'WDT'), ('use', 'VBP'), ('semantic', 'JJ'), ('approaches', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('template-based', 'JJ'), ('methods', 'NNS'), ('(', '('), Tree('ORGANIZATION', [('Genest', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Lapalme', 'NNP')]), (',', ','), ('2011', 'CD'), (')', ')'), ('and', 'CC'), ('ontology-based', 'JJ'), ('methods', 'NNS'), ('(', '('), ('Chang-Shing', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2005', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('More', 'RBR'), ('recently', 'RB'), ('research', 'NN'), ('on', 'IN'), ('abstractive', 'JJ'), ('summarizing', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('inspired', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('encoder-decoder', 'NN'), ('framework', 'NN'), (',', ','), ('as', 'IN'), ('in', 'IN'), ('research', 'NN'), ('conducted', 'VBN'), ('by', 'IN'), ('Xu', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('(', '('), ('2020', 'CD'), (')', ')'), (';', ':'), Tree('PERSON', [('Lee', 'NNP')]), ('et', 'FW'), ('al', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('(', '('), ('2020', 'CD'), (')', ')'), (';', ':'), Tree('PERSON', [('Yao', 'NNP')]), ('et', 'FW'), ('al', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('(', '('), ('2018a', 'CD'), (')', ')'), (';', ':'), Tree('PERSON', [('Iwasaki', 'NNP')]), ('et', 'FW'), ('al', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('(', '('), ('2019', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('Besides', 'IN'), ('being', 'VBG'), ('believed', 'VBN'), ('that', 'IN'), ('this', 'DT'), ('model', 'NN'), ('is', 'VBZ'), ('smoother', 'RB'), (',', ','), ('the', 'DT'), ('encoder-decoder', 'JJ'), ('framework', 'NN'), ('is', 'VBZ'), ('also', 'RB'), ('convenient', 'JJ'), ('in', 'IN'), ('adjusting', 'VBG'), ('parameters', 'NNS'), ('automatically', 'RB'), ('(', '('), ('Xu', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2020', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('In', 'IN'), ('the', 'DT'), ('2000s', 'CD'), (',', ','), ('there', 'EX'), ('was', 'VBD'), ('a', 'DT'), ('renewed', 'VBN'), ('trend', 'NN'), ('in', 'IN'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), ('text', 'JJ'), ('summarizing', 'VBG'), ('research', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('Summaries', 'NNS'), ('are', 'VBP'), ('not', 'RB'), ('only', 'RB'), ('generated', 'VBD'), ('once', 'RB'), ('but', 'CC'), ('are', 'VBP'), ('also', 'RB'), ('able', 'JJ'), ('to', 'TO'), ('summarize', 'VB'), ('events', 'NNS'), ('in', 'IN'), ('real-time', 'NN'), ('or', 'CC'), ('update', 'JJ'), ('summaries', 'NNS'), ('when', 'WRB'), ('new', 'JJ'), ('information', 'NN'), ('appears', 'VBZ'), ('called', 'VBN'), ('real-time', 'JJ'), ('summarization', 'NN'), ('(', '('), ('Ekstrand-abueg', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (',', ','), Tree('PERSON', [('Lou', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Man', 'NNP')]), (',', ','), ('2012', 'CD'), (',', ','), Tree('GPE', [('H', 'NNP')]), (',', ','), Tree('GPE', [('A.S.S.', 'NNP')]), (',', ','), Tree('GPE', [('K', 'NNP')]), (',', ','), Tree('GPE', [('M.M.C.', 'NNP')]), (',', ','), (',', ','), ('2016', 'CD'), (',', ','), Tree('PERSON', [('Maio', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (',', ','), ('Rodríguez-Vidal', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (',', ','), Tree('PERSON', [('Kacprzyk', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2008', 'CD'), (',', ','), ('Fu', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (',', ','), ('Wu', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015a', 'CD'), (',', ','), ('Wu', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015b', 'CD'), (',', ','), Tree('PERSON', [('Wang', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [Tree('GPE', [('Approach', 'NN')]), ('techniques', 'NNS'), ('that', 'WDT'), ('have', 'VBP'), ('been', 'VBN'), ('used', 'VBN'), ('in', 'IN'), ('real-time', 'JJ'), ('summarization', 'NN'), ('are', 'VBP'), ('fuzzy-based', 'JJ'), ('and', 'CC'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('An', 'DT'), ('example', 'NN'), ('of', 'IN'), ('a', 'DT'), ('method', 'NN'), ('that', 'WDT'), ('uses', 'VBZ'), ('a', 'DT'), ('fuzzy-based', 'JJ'), ('approach', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('fuzzy', 'JJ'), ('logic', 'NN'), ('with', 'IN'), ('classic', 'JJ'), Tree('PERSON', [('Zadeh', 'NNP')]), (\"'s\", 'POS'), ('calculus', 'NN'), ('of', 'IN'), ('linguistically', 'RB'), ('quantified', 'VBN'), ('propositions', 'NNS'), ('(', '('), Tree('ORGANIZATION', [('Kacprzyk', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2008', 'CD'), (')', ')'), ('which', 'WDT'), ('addresses', 'VBZ'), ('trend', 'NN'), ('extraction', 'NN'), ('and', 'CC'), ('real-time', 'NN'), ('problems', 'NNS'), ('where', 'WRB'), ('the', 'DT'), ('results', 'NNS'), ('are', 'VBP'), ('superior', 'JJ'), ('in', 'IN'), ('t-norm', 'JJ'), ('evaluation', 'NN'), (',', ','), ('but', 'CC'), ('weak', 'JJ'), ('in', 'IN'), ('semantic', 'JJ'), ('problems', 'NNS'), ('because', 'IN'), ('the', 'DT'), ('semantic', 'JJ'), ('results', 'NNS'), ('of', 'IN'), ('other', 'JJ'), ('t-norms', 'NNS'), ('are', 'VBP'), ('unclear', 'JJ'), ('and', 'CC'), ('unclear', 'JJ'), ('can', 'MD'), ('be', 'VB'), ('understood', 'JJ'), ('.', '.')]),\n",
              " Tree('S', [Tree('PERSON', [('Fuzzy', 'NNP')]), Tree('ORGANIZATION', [('Formal', 'NNP'), ('Concept', 'NNP'), ('Analysis', 'NNP')]), ('(', '('), Tree('PERSON', [('Fuzzy', 'NNP'), ('FCA', 'NNP')]), (')', ')'), ('(', '('), Tree('ORGANIZATION', [('Maio', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('which', 'WDT'), ('addresses', 'VBZ'), ('semantic', 'JJ'), ('and', 'CC'), ('real', 'JJ'), ('time', 'NN'), ('problems', 'NNS'), ('where', 'WRB'), ('the', 'DT'), ('results', 'NNS'), ('excel', 'VBP'), ('at', 'IN'), ('evaluations', 'NNS'), ('in', 'IN'), ('f-measures', 'NNS'), ('with', 'IN'), ('optimal', 'JJ'), ('recall', 'NN'), ('and', 'CC'), ('comparable', 'JJ'), ('precision', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('An', 'DT'), ('example', 'NN'), ('of', 'IN'), ('a', 'DT'), ('method', 'NN'), ('that', 'WDT'), ('uses', 'VBZ'), ('a', 'DT'), ('machine', 'NN'), ('learning', 'VBG'), ('approach', 'NN'), ('is', 'VBZ'), Tree('ORGANIZATION', [('Incremental', 'NNP'), ('Short', 'NNP'), ('Text', 'NNP'), ('Summarization', 'NNP')]), ('(', '('), Tree('ORGANIZATION', [('IncreSTS', 'NNP')]), (')', ')'), ('by', 'IN'), Tree('PERSON', [('Liu', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015a', 'CD'), (',', ','), Tree('PERSON', [('Liu', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015b', 'CD'), ('which', 'WDT'), ('has', 'VBZ'), ('better', 'JJR'), ('outlier', 'NN'), ('handling', 'NN'), (',', ','), ('high', 'JJ'), ('efficiency', 'NN'), (',', ','), ('and', 'CC'), ('scalability', 'NN'), ('on', 'IN'), ('target', 'NN'), ('problems', 'NNS'), ('.', '.')]),\n",
              " Tree('S', [('Rank-biased', 'JJ'), ('precision-summarization', 'NN'), ('(', '('), ('RBP-SUM', 'NNP'), (')', ')'), ('by', 'IN'), ('Rodríguez-Vidal', 'NNP'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('(', '('), ('2019', 'CD'), (')', ')'), ('which', 'WDT'), ('has', 'VBZ'), ('advantages', 'NNS'), ('in', 'IN'), ('overcoming', 'VBG'), ('redundancy', 'NN'), ('by', 'IN'), ('evaluating', 'VBG'), ('using', 'VBG'), ('rouge', 'NN'), (',', ','), ('but', 'CC'), ('this', 'DT'), ('method', 'NN'), ('can', 'MD'), ('only', 'RB'), ('produce', 'VB'), ('extractive', 'JJ'), ('summaries', 'NNS'), ('.', '.')]),\n",
              " Tree('S', [Tree('GPE', [('Text', 'NNP')]), ('summarization', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('formidable', 'JJ'), ('challenge', 'NN'), ('in', 'IN'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), Tree('ORGANIZATION', [('Natural', 'NNP'), ('Language', 'NNP')]), ('Processing', 'NNP'), ('(', '('), Tree('ORGANIZATION', [('NLP', 'NNP')]), (')', ')'), ('(', '('), Tree('ORGANIZATION', [('Rane', 'NNP')]), ('and', 'CC'), Tree('GPE', [('Govilkar', 'NNP')]), (',', ','), ('2019', 'CD'), (',', ','), Tree('PERSON', [('Shabbir', 'NNP'), ('Moiyadi', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('because', 'IN'), ('it', 'PRP'), ('requires', 'VBZ'), ('precise', 'JJ'), ('text', 'JJ'), ('analysis', 'NN'), ('such', 'JJ'), ('as', 'IN'), ('semantic', 'JJ'), ('analysis', 'NN'), ('and', 'CC'), ('lexical', 'JJ'), ('analysis', 'NN'), ('to', 'TO'), ('produce', 'VB'), ('a', 'DT'), ('good', 'JJ'), ('summary', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('A', 'DT'), ('good', 'JJ'), ('summary', 'NN'), (',', ','), ('in', 'IN'), ('addition', 'NN'), (',', ','), ('must', 'MD'), ('contain', 'VB'), ('important', 'JJ'), ('information', 'NN'), ('and', 'CC'), ('must', 'MD'), ('be', 'VB'), ('concise', 'NN'), ('but', 'CC'), ('also', 'RB'), ('must', 'MD'), ('consider', 'VB'), ('aspects', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('non-redundancy', 'NN'), (',', ','), ('relevance', 'NN'), (',', ','), ('coverage', 'NN'), (',', ','), ('coherence', 'NN'), (',', ','), ('and', 'CC'), ('readability', 'NN'), ('(', '('), Tree('PERSON', [('Verma', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('Where', 'WRB'), ('to', 'TO'), ('get', 'VB'), ('all', 'PDT'), ('these', 'DT'), ('aspects', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('summary', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('great', 'JJ'), ('challenge', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('The', 'DT'), ('review', 'NN'), ('of', 'IN'), ('papers', 'NNS'), ('on', 'IN'), ('text', 'JJ'), ('summarization', 'NN'), ('is', 'VBZ'), ('important', 'JJ'), ('because', 'IN'), ('summarizing', 'VBG'), ('extractive', 'JJ'), ('techniques', 'NNS'), ('has', 'VBZ'), ('become', 'VBN'), ('a', 'DT'), ('very', 'RB'), ('broad', 'JJ'), ('research', 'NN'), ('topic', 'NN'), ('and', 'CC'), ('is', 'VBZ'), ('heading', 'VBG'), ('towards', 'NNS'), ('maturity', 'NN'), ('(', '('), Tree('PERSON', [('Gupta', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Gupta', 'NNP')]), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('Now', 'RB'), ('research', 'NN'), ('has', 'VBZ'), ('shifted', 'VBN'), ('towards', 'NNS'), ('abstractive', 'JJ'), ('summarization', 'NN'), ('(', '('), Tree('PERSON', [('Gupta', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Gupta', 'NNP')]), (',', ','), ('2019', 'CD'), (')', ')'), ('and', 'CC'), ('real-time', 'JJ'), ('summarization', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('This', 'DT'), ('is', 'VBZ'), ('because', 'RB'), ('abstractive', 'JJ'), ('summaries', 'NNS'), ('are', 'VBP'), ('more', 'RBR'), ('complex', 'JJ'), ('and', 'CC'), ('complicated', 'VBN'), ('than', 'IN'), ('extractive', 'JJ'), ('summaries', 'NNS'), ('.', '.')]),\n",
              " Tree('S', [('So', 'RB'), ('extractive', 'JJ'), ('summaries', 'NNS'), ('are', 'VBP'), ('easier', 'JJR'), ('to', 'TO'), ('give', 'VB'), ('expected', 'VBN'), ('and', 'CC'), ('better', 'JJR'), ('results', 'NNS'), ('than', 'IN'), ('abstractive', 'JJ'), ('summaries', 'NNS'), ('(', '('), Tree('ORGANIZATION', [('Elrefaiy', 'NNP')]), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (',', ','), Tree('PERSON', [('Allahyari', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2017', 'CD'), (',', ','), Tree('PERSON', [('Mishra', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Gayen', 'NNP')]), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('However', 'RB'), (',', ','), ('extractive', 'JJ'), ('summarization', 'NN'), ('is', 'VBZ'), ('also', 'RB'), ('still', 'RB'), ('in', 'IN'), ('great', 'JJ'), ('demand', 'NN'), ('as', 'IN'), ('evident', 'JJ'), ('extractive', 'JJ'), ('research', 'NN'), ('still', 'RB'), ('exists', 'VBZ'), ('in', 'IN'), ('the', 'DT'), ('last', 'JJ'), ('two', 'CD'), ('years', 'NNS'), ('(', '('), Tree('ORGANIZATION', [('Ren', 'NNP')]), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (',', ','), ('Sanchez-gomez', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2018', 'CD'), (',', ','), Tree('PERSON', [('Yao', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2018b', 'CD'), (',', ','), Tree('PERSON', [('Khan', 'NNP')]), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (',', ','), Tree('PERSON', [('Qaroush', 'NNP')]), ('et', 'CC'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (',', ','), Tree('GPE', [('Anand', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Wagh', 'NNP')]), (',', ','), ('2019', 'CD'), (',', ','), Tree('PERSON', [('Lierde', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Chow', 'NNP')]), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]),\n",
              " Tree('S', [('This', 'DT'), ('indicates', 'VBZ'), ('the', 'DT'), ('possibility', 'NN'), ('that', 'IN'), ('there', 'EX'), ('are', 'VBP'), ('still', 'RB'), ('opportunities', 'NNS'), ('or', 'CC'), ('loopholes', 'NNS'), ('to', 'TO'), ('improve', 'VB'), ('.', '.')]),\n",
              " Tree('S', [('A', 'DT'), ('clear', 'JJ'), ('literature', 'NN'), ('study', 'NN'), ('is', 'VBZ'), ('demanded', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('means', 'NN'), ('for', 'IN'), ('the', 'DT'), ('advancement', 'NN'), ('of', 'IN'), ('research', 'NN'), ('in', 'IN'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), ('text', 'JJ'), ('summarization', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('Where', 'WRB'), ('literature', 'NN'), ('studies', 'NNS'), ('are', 'VBP'), ('generally', 'RB'), ('contained', 'VBN'), (',', ','), ('analyzed', 'VBN'), (',', ','), ('and', 'CC'), ('compared', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('review', 'NN'), ('or', 'CC'), ('survey', 'NN'), ('paper', 'NN'), ('.', '.')]),\n",
              " Tree('S', [Tree('GPE', [('Review', 'NNP')]), ('paper', 'NN'), ('made', 'VBN'), ('by', 'IN'), Tree('PERSON', [('Gupta', 'NNP')]), ('and', 'CC'), Tree('GPE', [('Gupta', 'NNP')]), ('(', '('), ('2019', 'CD'), (')', ')'), ('discusses', 'VBZ'), ('popular', 'JJ'), ('components', 'NNS'), ('specifically', 'RB'), ('about', 'IN'), ('abstractive', 'JJ'), ('summarizing', 'NN'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('research', 'NN'), ('trends', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), ('abstractive', 'JJ'), ('summarization', 'NN'), (',', ','), ('general', 'JJ'), ('description', 'NN'), ('of', 'IN'), ('existing', 'VBG'), ('abstractive', 'JJ'), ('summarizing', 'NN'), ('techniques', 'NNS'), (',', ','), ('tools', 'NNS'), (',', ','), ('and', 'CC'), ('evaluations', 'NNS'), ('.', '.')]),\n",
              " Tree('S', [('Other', 'JJ'), ('reviews', 'NNS'), ('were', 'VBD'), ('conducted', 'VBN'), ('by', 'IN'), Tree('PERSON', [('Abualigah', 'NNP')]), ('et', 'CC'), ('al', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('(', '('), ('2020', 'CD'), (')', ')'), ('gave', 'VBD'), ('a', 'DT'), ('brief', 'JJ'), ('survey', 'NN'), ('of', 'IN'), ('the', 'DT'), ('techniques', 'NNS'), ('of', 'IN'), ('text', 'JJ'), ('summarization', 'NN'), ('and', 'CC'), ('specifically', 'RB'), ('in', 'IN'), Tree('GPE', [('Arabic', 'NNP')]), ('.', '.')]),\n",
              " Tree('S', [('A', 'DT'), ('survey', 'NN'), ('conducted', 'VBN'), ('by', 'IN'), Tree('PERSON', [('Nazari', 'NNP')]), ('and', 'CC'), Tree('GPE', [('Mahdavi', 'NNP')]), ('(', '('), ('2018', 'CD'), (')', ')'), ('discussing', 'VBG'), ('text', 'JJ'), ('summarization', 'NN'), ('focuses', 'VBZ'), ('on', 'IN'), ('the', 'DT'), ('approach', 'NN'), ('techniques', 'NNS'), ('and', 'CC'), ('methods', 'NNS'), ('used', 'VBN'), ('in', 'IN'), ('text', 'JJ'), ('summarization', 'NN'), ('.', '.')]),\n",
              " Tree('S', [Tree('GPE', [('Nazari', 'NNP')]), ('and', 'CC'), Tree('GPE', [('Mahdavi', 'NNP')]), ('(', '('), ('2018', 'CD'), (')', ')'), ('grouped', 'VBD'), ('approaches', 'NNS'), ('to', 'TO'), ('statistics', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('semantic-based', 'JJ'), (',', ','), ('and', 'CC'), ('swarm', 'JJ'), ('intelligence', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('Another', 'DT'), ('survey', 'NN'), ('was', 'VBD'), ('conducted', 'VBN'), ('by', 'IN'), Tree('PERSON', [('Elrefaiy', 'NNP')]), ('et', 'CC'), ('al', 'NN'), ('.', '.')]),\n",
              " Tree('S', [('(', '('), ('2018', 'CD'), (')', ')'), ('which', 'WDT'), ('is', 'VBZ'), ('about', 'IN'), ('summarizing', 'VBG'), ('extractive', 'JJ'), ('texts', 'NN'), ('that', 'WDT'), ('focus', 'NN'), ('on', 'IN'), ('unattended', 'JJ'), ('techniques', 'NNS'), (',', ','), ('presents', 'VBZ'), ('a', 'DT'), ('list', 'NN'), ('of', 'IN'), ('strengths', 'NNS'), ('and', 'CC'), ('weaknesses', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('comparison', 'NN'), ('table', 'NN'), (',', ','), ('alluding', 'VBG'), ('to', 'TO'), ('a', 'DT'), ('little', 'JJ'), ('about', 'IN'), ('evaluations', 'NNS'), ('and', 'CC'), ('future', 'JJ'), ('trends', 'NNS'), ('.', '.')])]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "doc = s(\" \".join([\" \".join(i)+\"\\n\" for i in words]))\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FfBh1_HhzLzZ",
        "outputId": "33deab33-1016-4904-9cfa-4302cc63423f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Along growth internet big data , making people overwhelmed large information document internet .</br> This trigger desire researcher develop technological approach summarize text automatically .</br> Automatic text summarization generates summary containing important sentence includes important relevant information original document ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Allahyari\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2017\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Gambhir Gupta\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2017\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> So information quickly arrives doe lose original intent document ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Murad Martin\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2007\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> The area text summarization research ha studied \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    mid-20th century\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , discussed openly \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lun\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1958\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) statistical technique word frequency diagram .</br> Many different approach created date .</br> Based number document , single multi-document summarization .</br> Meanwhile , based summary result extractive abstractive result .</br> A single document produce summary sourced source document ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Radev\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2001\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) content described topic .</br> While multi-document summarization taken source document discus topic ( Qiang et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2016\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ansamma et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2017\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , Widjanarko et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> ( Christian et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2016\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) text summarizing single document \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    TF-IDF\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ( \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sarkar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2013\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) designed automatic text summarizing single document \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Main Concepts\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " .</br> ( Qiang et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2016\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) summarized multiple document pattern-based summarization ( Patsum ) method \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2004\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " DUC dataset showed result outperformed term-based method ontology-based method .</br> Ansamma et al .</br> ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2017\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) summarized multiple document Latent Semantic Analysis ( LSA ) \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Non-Negative Matrix Factorization\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ( \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    NMF\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ) result outperformed state art precision recall .</br> Qaroush et al .</br> ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) proposes summarization \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Arabic\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " single document produce fairly informative extractive summary combining machine learning score-based approach evaluate sentence based combination semantics statistic .</br> The result superior term precision metric , memory , F-scores , disadvantage ha optimized weight feature .</br> Verma Om ( 2019 ) minimized redundancy multi-document summarizing \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Shark Smell Optimization\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ( \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    SSO\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ) method performance result far better previous summary method .</br> Extractive summarization summary summary consist entirely extracted content result summary sentence sentence word obtained original text ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Khan Salim\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2014\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> The usual problem raised extractive summarization research determining position sentence ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Khan Salim\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2014\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) frequency word text ( Baxendale , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1958\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> The experiment raised extraction problem known \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Information Extraction ( IE\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ) technique produce summary specific result increase accuracy .</br> \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    One\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " example automatic summarizing system ha developed adopting IE technique RIPTIDES , function summarize news based scenario chosen user ( White et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2001\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> Research \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Naik Gaonkar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2017\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) rule base produce best average precision , f-measure , recall value Rule-Based Summarizers ha tried broader data .</br> Furthermore , extractive summarizing study neural network , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    recent year\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " achieved greater popularity conventional approach , study ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mohsen\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Anand Wagh\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Xu Durrett\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Chen et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , 2018a , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Chen et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018b\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Alami et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> Research conducted \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Anand Wagh\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) deep learning \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    technique Feed Forward Neural Network\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ( \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    FFNN\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ) summarize single document legal document ha advantage producing extractive summary need create feature domain knowledge perform measured \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Rouge\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " score produce coherent summary , weak term simplifying complex long sentence .</br> In contrast extractive summarization , sentence generated abstractive summary new sentence commonly called paraphrase produce summary word text .</br> Abstractive summary complex relatively difficult extractive summary producing abstractive summary requires extensive natural language processing ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Gambhir Gupta\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2017\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> Approach technique abstractive summary generally grouped category linguistic approach semantic approach .</br> Examples method use linguistic approach information-based method ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Genest Lapalme\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2012\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) tree-based method ( Barzilay et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1999\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tanaka\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2009\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> While example method use semantic approach template-based method ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Genest Lapalme\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2011\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) ontology-based method ( \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Chang-Shing et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " , 2005 ) .</br> More recently research abstractive summarizing ha inspired encoder-decoder framework , research conducted \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Xu et al\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " .</br> ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) ; \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lee et al\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " .</br> ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) ; Yao et al .</br> ( 2018a ) ; \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Iwasaki et al\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " .</br> ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> Besides believed model smoother , encoder-decoder framework convenient adjusting parameter automatically ( Xu et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> In \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2000s\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , renewed trend field text summarizing research .</br> Summaries generated able summarize event real-time update summary new information appears called real-time summarization ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ekstrand\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "-abueg et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2016\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lou Man\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , 2012 , H , A.S.S. , K , M.M.C. , , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2016\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Maio et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2015\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Rodríguez-Vidal et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Kacprzyk et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " , 2008 , Fu et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2015\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Wu et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , 2015a , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Wu et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2015b\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , Wang et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2014\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> Approach technique real-time summarization fuzzy-based machine learning .</br> An example method fuzzy-based approach fuzzy logic classic \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Zadeh\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " calculus linguistically quantified proposition ( Kacprzyk et al. , 2008 ) address trend extraction real-time problem result superior t-norm evaluation , weak semantic problem semantic result t-norms unclear unclear understood .</br> Fuzzy Formal Concept Analysis ( Fuzzy FCA ) ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Maio\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2015\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) address semantic real time problem result excel evaluation f-measures optimal recall comparable precision .</br> An example method machine learning approach Incremental Short Text Summarization ( IncreSTS ) \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Liu et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , 2015a , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Liu et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2015b\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ha better outlier handling , high efficiency , scalability target problem .</br> Rank-biased precision-summarization ( RBP-SUM ) \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Rodríguez-Vidal et al\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " .</br> ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) ha advantage overcoming redundancy evaluating rouge , method produce extractive summary .</br> Text summarization formidable challenge field Natural Language Processing ( \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    NLP\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ) ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Rane Govilkar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Shabbir Moiyadi et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2016\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) requires precise text analysis semantic analysis lexical analysis produce good summary .</br> A good summary , addition , contain important information concise consider aspect non-redundancy , relevance , coverage , coherence , readability ( Verma et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> Where aspect summary great challenge .</br> The review paper text summarization important summarizing extractive technique ha broad research topic heading maturity ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Gupta Gupta\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> Now research ha shifted abstractive summarization ( \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Gupta Gupta\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) real-time summarization .</br> This abstractive summary complex complicated extractive summary .</br> So extractive summary easier expected better result abstractive summary ( Elrefaiy et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Allahyari\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2017\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mishra Gayen\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> However , extractive summarization great demand evident extractive research exists year ( Ren et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sanchez-gomez et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , Yao et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018b\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Khan et al.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Qaroush\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " et al. , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Anand Wagh\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lierde Chow\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) .</br> This indicates possibility opportunity loophole improve .</br> A clear literature study demanded mean advancement research field text summarization .</br> Where literature study generally contained , analyzed , compared review survey paper .</br> Review paper \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Gupta Gupta\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) discus popular component specifically abstractive summarizing , research trend field abstractive summarization , general description existing abstractive summarizing technique , tool , evaluation .</br> Other review conducted \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Abualigah et al\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " .</br> ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2020\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) gave brief survey technique text summarization specifically \n",
              "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Arabic\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
              "</mark>\n",
              " .</br> A survey conducted \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Nazari Mahdavi\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) discussing text summarization focus approach technique method text summarization .</br> Nazari Mahdavi ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) grouped approach statistic , machine learning , semantic-based , swarm intelligence .</br> Another survey conducted \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Elrefaiy et al\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " .</br> ( \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " ) summarizing extractive text focus unattended technique , present list strength weakness comparison table , alluding little evaluation future trend .</br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Noun Phrases"
      ],
      "metadata": {
        "id": "KMIoJfTMHiha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np = textacy.extract.noun_chunks(s(data), min_freq=2)\n",
        "l = []\n",
        "np=map(str,np)\n",
        "np = map(str.lower, np)\n",
        "for i in np:\n",
        "  if (len(i.split(' ')) > 1):\n",
        "    l.append(i)\n",
        "print(set(l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2oqKfyYHhL3",
        "outputId": "88f00752-7721-4988-daaa-16f5d65be4ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'single document', 'encoder-decoder framework', 'allahyari et al', 'et al', 'yao et al', 'kacprzyk et al', 'multiple documents', 'maio et al', 'abstractive summarizing', 'rodríguez-vidal et al', 'same topic', 'abstractive summarization', 'wu et al', 'real-time summarization', 'good summary', 'liu et al', 'ansamma et al', 'elrefaiy et al', 'abstractive summaries', 'extractive summaries', 'qaroush et al', 'extractive summarization', 'approach techniques', 'text summarization', 'xu et al'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dependancy Parsing"
      ],
      "metadata": {
        "id": "bKAEin1YPrGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in doc.sents:\n",
        "  for j in i:\n",
        "    print(\"{} : {}\".format(j.text,j.dep_),end=\" \")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zioJLP_xQ39z",
        "outputId": "703560ab-c292-4a76-d3f5-04b7946117e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Along : ROOT growth : compound internet : pobj big : amod data : pobj , : punct making : advcl people : nsubj overwhelmed : ccomp large : amod information : compound document : compound internet : dobj . : punct \n",
            "\n",
            "  : dep This : det trigger : compound desire : compound researcher : nsubj develop : prep technological : amod approach : dobj summarize : ROOT text : dobj automatically : advmod . : punct \n",
            "\n",
            "  : dep Automatic : amod text : compound summarization : nsubj generates : ROOT summary : dobj containing : acl important : amod sentence : dobj includes : advcl important : amod relevant : amod information : nmod original : amod document : dobj ( : punct Allahyari : compound et : compound al : appos . : conj , : punct 2017 : appos , : punct Gambhir : compound Gupta : appos , : punct 2017 : appos ) : punct . : punct \n",
            "\n",
            "  : dep \n",
            "So : advmod information : nsubj quickly : advmod arrives : ROOT doe : dobj lose : conj original : amod intent : compound document : dobj ( : punct Murad : compound Martin : appos , : punct 2007 : npadvmod ) : punct . : punct \n",
            "\n",
            "  : dep \n",
            "The : det area : compound text : compound summarization : compound research : nsubj ha : intj studied : ROOT mid-20th : nummod century : npadvmod , : punct discussed : conj openly : advmod Lun : nmod ( : punct 1958 : nummod ) : punct statistical : amod technique : compound word : compound frequency : compound diagram : dobj . : punct \n",
            "\n",
            "  : dep \n",
            "Many : amod different : amod approach : nsubj created : ROOT date : dobj . : punct \n",
            "\n",
            "  : dep \n",
            "Based : amod number : compound document : ROOT , : punct single : amod multi : amod - : amod document : amod summarization : appos . : punct \n",
            "\n",
            "  : dep \n",
            "Meanwhile : advmod , : punct based : amod summary : nsubj result : ROOT extractive : amod abstractive : compound result : dobj . : punct \n",
            "\n",
            "  : dep A : det single : amod document : compound produce : compound summary : nmod sourced : amod source : compound document : nsubj ( : punct Radev : compound et : compound al : appos . : nmod , : punct 2001 : npadvmod ) : punct content : appos described : ROOT topic : dobj . : punct \n",
            "\n",
            "  : dep While : mark multi : amod - : amod document : amod summarization : nsubj taken : advcl source : compound document : compound discus : compound topic : dobj ( : punct Qiang : compound et : compound al : appos . : dobj , : punct 2016 : appos , : punct Ansamma : compound et : compound al : npadvmod . : dobj , : punct 2017 : appos , : punct Widjanarko : compound et : compound al : npadvmod . : dobj , : punct 2018 : appos ) : punct . : punct \n",
            "\n",
            "  : dep ( : punct Christian : compound et : compound al : nsubj . : nsubj , : punct 2016 : nummod ) : punct text : appos summarizing : acl single : amod document : compound TF : compound - : punct IDF : dobj ( : punct Sarkar : appos , : punct 2013 : appos ) : punct designed : ROOT automatic : amod text : npadvmod summarizing : amod single : amod document : dobj Main : compound Concepts : appos . : punct \n",
            "\n",
            "  : dep ( : punct Qiang : compound et : compound al : nsubj . : nsubj , : punct 2016 : appos ) : punct summarized : ROOT multiple : amod document : npadvmod pattern : npadvmod - : punct based : amod summarization : dobj ( : punct Patsum : appos ) : punct method : dobj 2004 : nummod DUC : compound dataset : nsubj showed : relcl result : nsubj outperformed : ccomp term : npadvmod - : punct based : amod method : nmod ontology : npadvmod - : punct based : amod method : dobj . : punct \n",
            "\n",
            "  : dep \n",
            "Ansamma : compound et : nmod al : ROOT . : punct \n",
            "\n",
            "  : dep ( : punct 2017 : appos ) : punct summarized : ROOT multiple : amod document : dobj Latent : nmod Semantic : compound Analysis : nmod ( : punct LSA : appos ) : punct Non : compound - : amod Negative : compound Matrix : compound Factorization : nmod ( : punct NMF : appos ) : punct result : nsubj outperformed : conj state : compound art : compound precision : compound recall : dobj . : punct \n",
            "\n",
            "  : dep \n",
            "Qaroush : compound et : nmod al : ROOT . : punct \n",
            "\n",
            "  : dep ( : punct 2019 : appos ) : punct proposes : ROOT summarization : dobj Arabic : amod single : amod document : nsubj produce : relcl fairly : advmod informative : amod extractive : amod summary : dobj combining : acl machine : compound learning : dobj score : npadvmod - : punct based : amod approach : dobj evaluate : ccomp sentence : npadvmod based : amod combination : compound semantics : compound statistic : dobj . : punct \n",
            "\n",
            "  : dep \n",
            "The : det result : ROOT superior : amod term : compound precision : compound metric : appos , : punct memory : conj , : punct F : compound - : punct scores : conj , : punct disadvantage : nmod ha : prep optimized : amod weight : compound feature : conj . : punct \n",
            "\n",
            "  : dep Verma : compound Om : nsubj ( : punct 2019 : appos ) : punct minimized : aux redundancy : csubj multi : amod - : amod document : dobj summarizing : acl Shark : nmod Smell : nmod Optimization : nmod ( : punct SSO : appos ) : punct method : compound performance : dobj result : ROOT far : advmod better : amod previous : amod summary : compound method : dobj . : punct \n",
            "\n",
            "  : dep \n",
            "Extractive : amod summarization : compound summary : compound summary : nsubj consist : aux entirely : advmod extracted : amod content : compound result : compound summary : compound sentence : compound sentence : compound word : nsubj obtained : ROOT original : amod text : dobj ( : punct Khan : compound Salim : appos , : punct 2014 : appos ) : punct . : punct \n",
            "\n",
            "  : dep The : det usual : amod problem : nsubj raised : ROOT extractive : amod summarization : compound research : dobj determining : acl position : compound sentence : dobj ( : punct Khan : compound Salim : npadvmod , : punct 2014 : appos ) : punct frequency : amod word : compound text : appos ( : punct Baxendale : appos , : punct 1958 : appos ) : punct . : punct \n",
            "\n",
            "  : dep \n",
            "The : det experiment : nsubj raised : ROOT extraction : compound problem : dobj known : acl Information : nmod Extraction : nmod ( : punct IE : appos ) : punct technique : compound produce : compound summary : nmod specific : amod result : compound increase : compound accuracy : appos . : punct \n",
            "\n",
            "  : dep One : nummod example : nsubj automatic : amod summarizing : amod system : appos ha : punct developed : ccomp adopting : xcomp IE : compound technique : compound RIPTIDES : dobj , : punct function : nsubj summarize : ROOT news : npadvmod based : amod scenario : nmod chosen : amod user : dobj ( : punct White : compound et : compound al : appos . : appos , : punct 2001 : npadvmod ) : punct . : punct \n",
            "\n",
            "  : dep Research : compound Naik : compound Gaonkar : nsubj ( : punct 2017 : appos ) : punct rule : compound base : appos produce : ROOT best : amod average : amod precision : dobj , : punct f : npadvmod - : punct measure : dobj , : punct recall : conj value : dobj Rule : compound - : punct Based : compound Summarizers : dobj ha : intj tried : conj broader : amod data : dobj . : punct \n",
            "\n",
            "  : dep Furthermore : advmod , : punct extractive : amod summarizing : amod study : nmod neural : amod network : nsubj , : punct recent : amod year : npadvmod achieved : ROOT greater : amod popularity : nmod conventional : amod approach : dobj , : punct study : conj ( : punct Mohsen : compound et : compound al : appos . : dobj , : punct 2020 : appos , : punct Anand : compound Wagh : npadvmod , : punct 2019 : appos , : punct Xu : compound Durrett : appos , : punct 2019 : appos , : punct Chen : compound et : compound al : conj . : conj , : punct 2018a : appos , : punct Chen : compound et : compound al : appos . : conj , : punct 2018b : appos , : punct Alami : compound et : compound al : conj . : conj , : punct 2019 : appos ) : punct . : punct \n",
            "\n",
            "  : dep Research : nsubj conducted : relcl Anand : compound Wagh : dobj ( : punct 2019 : appos ) : punct deep : amod learning : compound technique : dobj Feed : compound Forward : compound Neural : compound Network : appos ( : punct FFNN : appos ) : punct summarize : ROOT single : amod document : nmod legal : amod document : dobj ha : intj advantage : appos producing : advcl extractive : amod summary : dobj need : dobj create : dep feature : compound domain : compound knowledge : dobj perform : conj measured : conj Rouge : compound score : compound produce : dobj coherent : amod summary : dobj , : punct weak : amod term : npadvmod simplifying : acl complex : amod long : amod sentence : dobj . : punct \n",
            "\n",
            "  : dep In : prep contrast : pobj extractive : amod summarization : pobj , : punct sentence : nsubj generated : ROOT abstractive : amod summary : nmod new : amod sentence : dobj commonly : advmod called : acl paraphrase : oprd produce : compound summary : compound word : compound text : conj . : punct \n",
            "\n",
            "  : dep \n",
            "Abstractive : amod summary : compound complex : nsubj relatively : advmod difficult : amod extractive : amod summary : appos producing : acl abstractive : compound summary : dobj requires : ROOT extensive : amod natural : amod language : compound processing : dobj ( : punct Gambhir : compound Gupta : appos , : punct 2017 : appos ) : punct . : punct \n",
            "\n",
            "  : dep \n",
            "Approach : compound technique : compound abstractive : compound summary : nsubj generally : advmod grouped : ROOT category : nmod linguistic : amod approach : compound semantic : compound approach : dobj . : punct \n",
            "\n",
            "  : dep Examples : compound method : nsubj use : ROOT linguistic : amod approach : nmod information : npadvmod - : punct based : amod method : dobj ( : punct Genest : compound Lapalme : appos , : punct 2012 : npadvmod ) : punct tree : npadvmod - : punct based : amod method : appos ( : punct Barzilay : appos et : npadvmod al : npadvmod . : dobj , : punct 1999 : appos , : punct Tanaka : compound et : compound al : appos . : appos , : punct 2009 : appos ) : punct . : punct \n",
            "\n",
            "  : dep \n",
            "While : mark example : compound method : nsubj use : ROOT semantic : amod approach : nmod template : npadvmod - : punct based : amod method : dobj ( : punct Genest : compound Lapalme : appos , : punct 2011 : npadvmod ) : punct ontology : npadvmod - : punct based : amod method : appos ( : punct Chang : compound - : punct Shing : compound et : compound al : npadvmod . : dobj , : punct 2005 : npadvmod ) : punct . : punct \n",
            "\n",
            "  : dep More : advmod recently : advmod research : compound abstractive : compound summarizing : ccomp ha : intj inspired : amod encoder : compound - : punct decoder : compound framework : dobj , : punct research : nsubj conducted : ROOT Xu : compound et : nmod al : dobj . : punct \n",
            "\n",
            "  : dep ( : punct 2020 : appos ) : punct ; : punct Lee : compound et : compound al : conj . : punct \n",
            "\n",
            "  : dep ( : punct 2020 : appos ) : punct ; : punct Yao : compound et : compound al : conj . : punct \n",
            "\n",
            "  : dep ( : punct 2018a : appos ) : punct ; : punct Iwasaki : compound et : compound al : conj . : punct \n",
            "\n",
            "  : dep ( : punct 2019 : appos ) : punct . : punct \n",
            "\n",
            "  : dep \n",
            "Besides : advmod believed : advcl model : dobj smoother : amod , : punct encoder : compound - : punct decoder : compound framework : ROOT convenient : amod adjusting : compound parameter : appos automatically : advmod ( : punct Xu : compound et : compound al : appos . : appos , : punct 2020 : npadvmod ) : punct . : punct \n",
            "\n",
            "  : dep \n",
            "In : prep 2000s : pobj , : punct renewed : amod trend : compound field : compound text : npadvmod summarizing : amod research : ROOT . : punct \n",
            "\n",
            "  : dep Summaries : nsubj generated : acl able : aux summarize : ROOT event : nmod real : amod - : punct time : compound update : compound summary : compound new : amod information : nsubj appears : ccomp called : xcomp real : amod - : punct time : compound summarization : oprd ( : punct Ekstrand : compound - : punct abueg : appos et : compound al : appos . : appos , : punct 2016 : appos , : punct Lou : compound Man : appos , : punct 2012 : appos , : punct H : conj , : punct A.S.S. : conj , : punct K : conj , : punct M.M.C. : conj , : punct , : punct 2016 : conj , : punct Maio : compound et : compound al : conj . : conj , : punct 2015 : appos , : punct Rodríguez : npadvmod - : punct Vidal : amod et : nmod al : appos . : appos , : punct 2019 : appos , : punct Kacprzyk : compound et : compound al : appos . : appos , : punct 2008 : appos , : punct Fu : compound et : compound al : appos . : appos , : punct 2015 : appos , : punct Wu : compound et : compound al : appos . : appos , : punct 2015a : appos , : punct Wu : compound et : compound al : appos . : appos , : punct 2015b : appos , : punct Wang : compound et : compound al : appos . : appos , : punct 2014 : appos ) : punct . : punct \n",
            "\n",
            "  : dep Approach : compound technique : ROOT real : amod - : punct time : compound summarization : nmod fuzzy : npadvmod - : punct based : amod machine : compound learning : dobj . : punct \n",
            "\n",
            "  : dep \n",
            "An : det example : compound method : nsubj fuzzy : npadvmod - : punct based : amod approach : nmod fuzzy : amod logic : appos classic : amod Zadeh : compound calculus : nmod linguistically : advmod quantified : amod proposition : appos ( : punct Kacprzyk : compound et : compound al : appos . : appos , : punct 2008 : appos ) : punct address : nsubj trend : nmod extraction : nmod real : amod - : punct time : compound problem : dobj result : ccomp superior : amod t : compound - : punct norm : compound evaluation : dobj , : punct weak : amod semantic : amod problem : compound semantic : amod result : compound t : compound - : punct norms : nsubj unclear : advmod unclear : advmod understood : ROOT . : punct \n",
            "\n",
            "  : dep \n",
            "Fuzzy : compound Formal : compound Concept : compound Analysis : nsubj ( : punct Fuzzy : compound FCA : appos ) : punct ( : punct Maio : compound et : compound al : appos . : punct , : punct 2015 : appos ) : punct address : ROOT semantic : amod real : amod time : compound problem : compound result : dobj excel : dep evaluation : dobj f : punct - : punct measures : nmod optimal : amod recall : dep comparable : amod precision : dobj . : punct \n",
            "\n",
            "  : dep An : det example : compound method : compound machine : compound learning : nsubj approach : ROOT Incremental : compound Short : compound Text : compound Summarization : dobj ( : punct IncreSTS : appos ) : punct \n",
            "Liu : compound et : compound al : ROOT . : appos , : punct 2015a : appos , : punct Liu : compound et : compound al : appos . : appos , : punct 2015b : nummod ha : punct better : amod outlier : compound handling : appos , : punct high : amod efficiency : conj , : punct scalability : compound target : compound problem : conj . : punct \n",
            "\n",
            "  : dep Rank : npadvmod - : punct biased : amod precision : compound - : punct summarization : nmod ( : punct RBP : nmod - : punct SUM : appos ) : punct Rodríguez : npadvmod - : punct Vidal : amod et : nmod al : punct . : punct \n",
            "\n",
            "  : dep ( : punct 2019 : appos ) : punct ha : compound advantage : appos overcoming : acl redundancy : dobj evaluating : acl rouge : dobj , : punct method : appos produce : ROOT extractive : amod summary : dobj . : punct \n",
            "\n",
            "  : dep Text : compound summarization : nmod formidable : amod challenge : compound field : ROOT Natural : compound Language : compound Processing : appos ( : punct NLP : appos ) : punct \n",
            "( : punct Rane : compound Govilkar : nsubj , : punct 2019 : appos , : punct Shabbir : compound Moiyadi : conj et : compound al : appos . : nsubj , : punct 2016 : appos ) : punct requires : ROOT precise : amod text : compound analysis : dobj semantic : amod analysis : nmod lexical : amod analysis : nsubj produce : ccomp good : amod summary : dobj . : punct \n",
            "\n",
            "  : dep A : det good : amod summary : nsubj , : punct addition : nsubj , : punct contain : ROOT important : amod information : dobj concise : amod consider : relcl aspect : dobj non : dobj - : conj redundancy : conj , : punct relevance : conj , : punct coverage : conj , : punct coherence : conj , : punct readability : conj ( : punct Verma : compound et : compound al : dobj . : dobj , : punct 2019 : appos ) : punct . : punct \n",
            "\n",
            "  : dep Where : advmod aspect : compound summary : compound great : amod challenge : ROOT . : punct \n",
            "\n",
            "  : dep \n",
            "The : det review : compound paper : compound text : compound summarization : ROOT important : amod summarizing : amod extractive : amod technique : appos ha : intj broad : amod research : compound topic : compound heading : compound maturity : appos ( : punct Gupta : compound Gupta : appos , : punct 2019 : appos ) : punct . : punct \n",
            "\n",
            "  : dep Now : advmod research : nsubj ha : intj shifted : ROOT abstractive : amod summarization : dobj ( : punct Gupta : compound Gupta : appos , : punct 2019 : appos ) : punct real : amod - : punct time : compound summarization : conj . : punct \n",
            "\n",
            "  : dep \n",
            "This : det abstractive : amod summary : nmod complex : amod complicated : amod extractive : amod summary : ROOT . : punct \n",
            "\n",
            "  : dep \n",
            "So : advmod extractive : amod summary : nsubj easier : advmod expected : ROOT better : advmod result : ccomp abstractive : amod summary : dobj ( : punct Elrefaiy : compound et : compound al : appos . : appos , : punct 2018 : appos , : punct Allahyari : compound et : compound al : appos . : appos , : punct 2017 : appos , : punct Mishra : compound Gayen : appos , : punct 2018 : appos ) : punct . : punct \n",
            "\n",
            "  : dep \n",
            "However : advmod , : punct extractive : amod summarization : nmod great : amod demand : nmod evident : amod extractive : amod research : nsubj exists : ROOT year : npadvmod ( : punct Ren : compound et : compound al : appos . : appos , : punct 2018 : appos , : punct Sanchez : compound - : punct gomez : compound et : compound al : appos . : appos , : punct 2018 : appos , : punct Yao : compound et : compound al : appos . : conj , : punct 2018b : appos , : punct Khan : compound et : compound al : appos . : conj , : punct 2019 : appos , : punct Qaroush : compound et : compound al : appos . : conj , : punct 2019 : appos , : punct Anand : compound Wagh : appos , : punct 2019 : appos , : punct Lierde : compound Chow : appos , : punct 2019 : npadvmod ) : punct . : punct \n",
            "\n",
            "  : dep This : nsubj indicates : ROOT possibility : compound opportunity : compound loophole : compound improve : ccomp . : punct \n",
            "\n",
            "  : dep A : det clear : amod literature : compound study : nsubj demanded : ROOT mean : ccomp advancement : compound research : compound field : compound text : compound summarization : dobj . : punct \n",
            "\n",
            "  : dep Where : advmod literature : compound study : nsubj generally : advmod contained : relcl , : punct analyzed : conj , : punct compared : prep review : compound survey : compound paper : pobj . : punct \n",
            "\n",
            "  : dep Review : compound paper : compound Gupta : compound Gupta : nsubj ( : punct 2019 : appos ) : punct discus : nmod popular : amod component : ROOT specifically : advmod abstractive : amod summarizing : appos , : punct research : compound trend : compound field : compound abstractive : compound summarization : conj , : punct general : amod description : nmod existing : amod abstractive : compound summarizing : compound technique : conj , : punct tool : conj , : punct evaluation : conj . : punct \n",
            "\n",
            "  : dep \n",
            "Other : amod review : nsubj conducted : ROOT Abualigah : compound et : nmod al : dobj . : punct \n",
            "\n",
            "  : dep ( : punct 2020 : appos ) : punct gave : ROOT brief : amod survey : compound technique : compound text : compound summarization : dobj specifically : advmod Arabic : amod . : punct \n",
            "\n",
            "  : dep A : det survey : nsubj conducted : ROOT Nazari : compound Mahdavi : dobj ( : punct 2018 : appos ) : punct discussing : advcl text : compound summarization : compound focus : compound approach : compound technique : compound method : compound text : compound summarization : dobj . : punct \n",
            "\n",
            "  : dep Nazari : compound Mahdavi : nsubj ( : punct 2018 : appos ) : punct grouped : ROOT approach : compound statistic : dobj , : punct machine : compound learning : conj , : punct semantic : npadvmod - : punct based : amod , : punct swarm : compound intelligence : conj . : punct \n",
            "\n",
            "  : dep \n",
            "Another : det survey : nsubj conducted : ROOT Elrefaiy : nmod et : nmod al : dobj . : punct \n",
            "\n",
            "  : dep ( : punct 2018 : appos ) : punct summarizing : acl extractive : amod text : compound focus : nmod unattended : amod technique : dobj , : punct present : amod list : compound strength : compound weakness : compound comparison : compound table : conj , : punct alluding : advcl little : amod evaluation : nmod future : amod trend : dobj . : punct \n",
            "\n",
            " : dep \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for i in doc.sents:\n",
        "  if len(i)>2 : \n",
        "    displacy.render(i, jupyter=True, style='dep')\n",
        "    count+=1\n",
        "  if count>5: break"
      ],
      "metadata": {
        "id": "XZc2XshK4AHj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f0038fd-7c29-4a55-d00c-3cd623a3d72b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"76c34ce8867f4ec081095f320b291deb-0\" class=\"displacy\" width=\"2150\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Along</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">growth</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">internet</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">big</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">data ,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">making</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">people</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">overwhelmed</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">large</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">information</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">document</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">internet .</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-0\" stroke-width=\"2px\" d=\"M245,439.5 C245,352.0 380.0,352.0 380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-1\" stroke-width=\"2px\" d=\"M70,439.5 C70,264.5 385.0,264.5 385.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M385.0,441.5 L393.0,429.5 377.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-2\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-3\" stroke-width=\"2px\" d=\"M70,439.5 C70,89.5 745.0,89.5 745.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,441.5 L753.0,429.5 737.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-4\" stroke-width=\"2px\" d=\"M70,439.5 C70,2.0 925.0,2.0 925.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M925.0,441.5 L933.0,429.5 917.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-5\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,352.0 1255.0,352.0 1255.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,441.5 L1112,429.5 1128,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-6\" stroke-width=\"2px\" d=\"M945,439.5 C945,264.5 1260.0,264.5 1260.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1260.0,441.5 L1268.0,429.5 1252.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-7\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,177.0 1965.0,177.0 1965.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,441.5 L1462,429.5 1478,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,352.0 1780.0,352.0 1780.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-9\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,441.5 L1812,429.5 1828,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-76c34ce8867f4ec081095f320b291deb-0-10\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,89.5 1970.0,89.5 1970.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-76c34ce8867f4ec081095f320b291deb-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1970.0,441.5 L1978.0,429.5 1962.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9db0aa54a8d045cc9bbf4a9ef3407232-0\" class=\"displacy\" width=\"1975\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">\n",
              " </tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">SPACE</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">This</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">trigger</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">desire</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">researcher</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">develop</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">technological</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">approach</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">summarize</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">text</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">automatically .</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,2.0 1450.0,2.0 1450.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,177.0 740.0,177.0 740.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-2\" stroke-width=\"2px\" d=\"M420,439.5 C420,352.0 555.0,352.0 555.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,441.5 L412,429.5 428,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-4\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-5\" stroke-width=\"2px\" d=\"M70,439.5 C70,89.5 920.0,89.5 920.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,441.5 L928.0,429.5 912.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-6\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,352.0 1255.0,352.0 1255.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,441.5 L1112,429.5 1128,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-7\" stroke-width=\"2px\" d=\"M945,439.5 C945,264.5 1260.0,264.5 1260.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1260.0,441.5 L1268.0,429.5 1252.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-8\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,352.0 1605.0,352.0 1605.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1605.0,441.5 L1613.0,429.5 1597.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-9\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,264.5 1785.0,264.5 1785.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9db0aa54a8d045cc9bbf4a9ef3407232-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1785.0,441.5 L1793.0,429.5 1777.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8513bd9393704036a4380b3807fbc2d3-0\" class=\"displacy\" width=\"3900\" height=\"662.0\" direction=\"ltr\" style=\"max-width: none; height: 662.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">\n",
              " </tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">SPACE</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Automatic</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">text</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">summarization</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">generates</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">summary</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">containing</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">important</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">sentence</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">includes</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">important</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">relevant</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">information</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">original</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">document (</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">Allahyari</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">et</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">al. ,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">2017 ,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">Gambhir</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">Gupta ,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">2017 ) .</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-0\" stroke-width=\"2px\" d=\"M70,527.0 C70,177.0 740.0,177.0 740.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,529.0 L62,517.0 78,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-1\" stroke-width=\"2px\" d=\"M245,527.0 C245,352.0 555.0,352.0 555.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,529.0 L237,517.0 253,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-2\" stroke-width=\"2px\" d=\"M420,527.0 C420,439.5 550.0,439.5 550.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,529.0 L412,517.0 428,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-3\" stroke-width=\"2px\" d=\"M595,527.0 C595,439.5 725.0,439.5 725.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,529.0 L587,517.0 603,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-4\" stroke-width=\"2px\" d=\"M770,527.0 C770,439.5 900.0,439.5 900.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M900.0,529.0 L908.0,517.0 892.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-5\" stroke-width=\"2px\" d=\"M945,527.0 C945,439.5 1075.0,439.5 1075.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1075.0,529.0 L1083.0,517.0 1067.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-6\" stroke-width=\"2px\" d=\"M1295,527.0 C1295,439.5 1425.0,439.5 1425.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,529.0 L1287,517.0 1303,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-7\" stroke-width=\"2px\" d=\"M1120,527.0 C1120,352.0 1430.0,352.0 1430.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1430.0,529.0 L1438.0,517.0 1422.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-8\" stroke-width=\"2px\" d=\"M770,527.0 C770,89.5 1620.0,89.5 1620.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1620.0,529.0 L1628.0,517.0 1612.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-9\" stroke-width=\"2px\" d=\"M1820,527.0 C1820,177.0 2490.0,177.0 2490.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,529.0 L1812,517.0 1828,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-10\" stroke-width=\"2px\" d=\"M1995,527.0 C1995,264.5 2485.0,264.5 2485.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1995,529.0 L1987,517.0 2003,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-11\" stroke-width=\"2px\" d=\"M2170,527.0 C2170,352.0 2480.0,352.0 2480.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,529.0 L2162,517.0 2178,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-12\" stroke-width=\"2px\" d=\"M2345,527.0 C2345,439.5 2475.0,439.5 2475.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2345,529.0 L2337,517.0 2353,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-13\" stroke-width=\"2px\" d=\"M1645,527.0 C1645,89.5 2495.0,89.5 2495.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2495.0,529.0 L2503.0,517.0 2487.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-14\" stroke-width=\"2px\" d=\"M2695,527.0 C2695,352.0 3005.0,352.0 3005.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,529.0 L2687,517.0 2703,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-15\" stroke-width=\"2px\" d=\"M2870,527.0 C2870,439.5 3000.0,439.5 3000.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,529.0 L2862,517.0 2878,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-16\" stroke-width=\"2px\" d=\"M2520,527.0 C2520,264.5 3010.0,264.5 3010.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3010.0,529.0 L3018.0,517.0 3002.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-17\" stroke-width=\"2px\" d=\"M3045,527.0 C3045,439.5 3175.0,439.5 3175.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3175.0,529.0 L3183.0,517.0 3167.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-18\" stroke-width=\"2px\" d=\"M3395,527.0 C3395,439.5 3525.0,439.5 3525.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3395,529.0 L3387,517.0 3403,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-19\" stroke-width=\"2px\" d=\"M2520,527.0 C2520,2.0 3550.0,2.0 3550.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3550.0,529.0 L3558.0,517.0 3542.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8513bd9393704036a4380b3807fbc2d3-0-20\" stroke-width=\"2px\" d=\"M3570,527.0 C3570,439.5 3700.0,439.5 3700.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8513bd9393704036a4380b3807fbc2d3-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3700.0,529.0 L3708.0,517.0 3692.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8552e42e519e408abdbcdcfabccd9a3c-0\" class=\"displacy\" width=\"2150\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">So</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">information</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">quickly</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">arrives</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">doe</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">lose</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">original</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">intent</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">document (</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">Murad</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">Martin ,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">2007 ) .</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-4\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-7\" stroke-width=\"2px\" d=\"M945,264.5 C945,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,266.5 L1458.0,254.5 1442.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-9\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1795.0,266.5 L1803.0,254.5 1787.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8552e42e519e408abdbcdcfabccd9a3c-0-10\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,177.0 1965.0,177.0 1965.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8552e42e519e408abdbcdcfabccd9a3c-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1965.0,266.5 L1973.0,254.5 1957.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ae43fe2d9ee64ee4a343d788ac51d9f2-0\" class=\"displacy\" width=\"3200\" height=\"749.5\" direction=\"ltr\" style=\"max-width: none; height: 749.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">area</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">text</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">summarization</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">research</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">ha</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">INTJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">studied</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">mid-20th</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">century ,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">discussed</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">openly</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">Lun (</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">1958 )</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">statistical</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">technique</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">word</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">frequency</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">diagram .</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-0\" stroke-width=\"2px\" d=\"M70,614.5 C70,264.5 735.0,264.5 735.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,616.5 L62,604.5 78,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-1\" stroke-width=\"2px\" d=\"M245,614.5 C245,352.0 730.0,352.0 730.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,616.5 L237,604.5 253,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-2\" stroke-width=\"2px\" d=\"M420,614.5 C420,527.0 545.0,527.0 545.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,616.5 L412,604.5 428,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-3\" stroke-width=\"2px\" d=\"M595,614.5 C595,527.0 720.0,527.0 720.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,616.5 L587,604.5 603,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-4\" stroke-width=\"2px\" d=\"M770,614.5 C770,439.5 1075.0,439.5 1075.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,616.5 L762,604.5 778,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-5\" stroke-width=\"2px\" d=\"M770,614.5 C770,527.0 895.0,527.0 895.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">intj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M895.0,616.5 L903.0,604.5 887.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-6\" stroke-width=\"2px\" d=\"M1295,614.5 C1295,527.0 1420.0,527.0 1420.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,616.5 L1287,604.5 1303,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-7\" stroke-width=\"2px\" d=\"M1120,614.5 C1120,439.5 1425.0,439.5 1425.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1425.0,616.5 L1433.0,604.5 1417.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-8\" stroke-width=\"2px\" d=\"M1120,614.5 C1120,352.0 1605.0,352.0 1605.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1605.0,616.5 L1613.0,604.5 1597.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-9\" stroke-width=\"2px\" d=\"M1645,614.5 C1645,527.0 1770.0,527.0 1770.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1770.0,616.5 L1778.0,604.5 1762.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-10\" stroke-width=\"2px\" d=\"M1995,614.5 C1995,89.5 3020.0,89.5 3020.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1995,616.5 L1987,604.5 2003,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-11\" stroke-width=\"2px\" d=\"M2170,614.5 C2170,177.0 3015.0,177.0 3015.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,616.5 L2162,604.5 2178,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-12\" stroke-width=\"2px\" d=\"M2345,614.5 C2345,527.0 2470.0,527.0 2470.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2345,616.5 L2337,604.5 2353,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-13\" stroke-width=\"2px\" d=\"M2520,614.5 C2520,527.0 2645.0,527.0 2645.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2520,616.5 L2512,604.5 2528,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-14\" stroke-width=\"2px\" d=\"M2695,614.5 C2695,527.0 2820.0,527.0 2820.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,616.5 L2687,604.5 2703,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-15\" stroke-width=\"2px\" d=\"M2870,614.5 C2870,527.0 2995.0,527.0 2995.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,616.5 L2862,604.5 2878,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-16\" stroke-width=\"2px\" d=\"M1645,614.5 C1645,2.0 3025.0,2.0 3025.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ae43fe2d9ee64ee4a343d788ac51d9f2-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3025.0,616.5 L3033.0,604.5 3017.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8082973bea57430f84cc535e86748bf5-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Many</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">different</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">approach</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">created</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">date .</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8082973bea57430f84cc535e86748bf5-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8082973bea57430f84cc535e86748bf5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8082973bea57430f84cc535e86748bf5-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8082973bea57430f84cc535e86748bf5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8082973bea57430f84cc535e86748bf5-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8082973bea57430f84cc535e86748bf5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8082973bea57430f84cc535e86748bf5-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8082973bea57430f84cc535e86748bf5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}