Along with the growth of the internet and big data, making people overwhelmed by the large information and documents on the internet. This triggers the desire of many researchers to develop a technological approach that can summarize texts automatically. Automatic text summarization generates summaries containing important sentences and includes all important relevant information from the original document (Allahyari et al., 2017, Gambhir and Gupta, 2017). So the information quickly arrives and does not lose the original intent of the document (Murad and Martin, 2007). The area of text summarization research has been studied since the mid-20th century, which was first discussed openly by Lun (1958) with a statistical technique namely word frequency diagrams. Many different approaches have been created to date. Based on the number of the document, there is single and multi-document summarization. Meanwhile, based on the summary results there are the extractive and abstractive results.

A single document produces a summary that is sourced from one source document (Radev et al., 2001) and the content described is around the same topic. While the multi-document summarization is taken from various sources or documents that discuss the same topic (Qiang et al., 2016, Ansamma et al., 2017, Widjanarko et al., 2018). (Christian et al., 2016) made text summarizing in a single document using TF-IDF and (Sarkar, 2013) designed automatic text summarizing in a single document using the Main Concepts. (Qiang et al., 2016) summarized multiple documents by the pattern-based summarization (Patsum) method on the 2004 DUC dataset and showed that the results outperformed not only the term-based method but also the ontology-based method. Ansamma et al. (2017) summarized multiple documents using Latent Semantic Analysis (LSA) and Non-Negative Matrix Factorization (NMF) and the results outperformed the state of the art in precision and recall. Qaroush et al. (2019) proposes the summarization of the Arabic single document which produces a fairly informative extractive summary combining machine learning and score-based approaches that evaluate each sentence based on a combination of semantics and statistics. The results are superior in terms of precision metrics, memory, and F-scores, the disadvantage is that it has not optimized the weight of the features. Verma and Om (2019) minimized redundancy in multi-document summarizing by the Shark Smell Optimization (SSO) method and the performance results were far better than the previous summary method.

Extractive summarization is a summary that summaries consist entirely of extracted content so that the results of summary sentences are sentences or words obtained from the original text (Khan and Salim, 2014). The usual problem raised from the extractive summarization research at first was determining the position of the sentence (Khan and Salim, 2014) and the frequency of words in the text (Baxendale, 1958). The next experiment raised the extraction problem which is known as the Information Extraction (IE) technique to produce a summary with more specific results and to increase accuracy. One example of an automatic summarizing system that has been developed by adopting IE techniques is RIPTIDES, which functions to summarize news based on scenarios chosen by the user (White et al., 2001). Research by Naik and Gaonkar (2017) using a rule base produces the best average precision, f-measure, and recall values for Rule-Based Summarizers but has not yet been tried on broader data. Furthermore, there are extractive summarizing studies using neural networks, which in recent years have achieved greater popularity than conventional approaches, some of these studies are (Mohsen et al., 2020, Anand and Wagh, 2019, Xu and Durrett, 2019, Chen et al., 2018a, Chen et al., 2018b, Alami et al., 2019). Research conducted by Anand and Wagh (2019) used a deep learning technique namely Feed Forward Neural Network (FFNN) to summarize a single document in a legal document that has the advantage of producing an extractive summary without the need to create features or domain knowledge and perform well as measured by the Rouge score and produces a coherent summary, will but weak in terms of simplifying complex and long sentences.

In contrast to extractive summarization, sentences generated by abstractive summaries are new sentences or commonly called paraphrases which produce summaries using words that are not in the text. Abstractive summaries are very complex and relatively more difficult than extractive summaries because producing abstractive summaries requires extensive natural language processing (Gambhir and Gupta, 2017). Approach techniques in abstractive summary are generally grouped into two categories namely the linguistic approach and the semantic approach. Examples of methods that use linguistic approaches such as information-based methods (Genest and Lapalme, 2012) and tree-based methods (Barzilay et al., 1999, Tanaka et al., 2009). While examples of methods that use semantic approaches such as template-based methods (Genest and Lapalme, 2011) and ontology-based methods (Chang-Shing et al., 2005). More recently research on abstractive summarizing has been inspired by the encoder-decoder framework, as in research conducted by Xu et al. (2020); Lee et al. (2020); Yao et al. (2018a); Iwasaki et al. (2019). Besides being believed that this model is smoother, the encoder-decoder framework is also convenient in adjusting parameters automatically (Xu et al., 2020).

In the 2000s, there was a renewed trend in the field of text summarizing research. Summaries are not only generated once but are also able to summarize events in real-time or update summaries when new information appears called real-time summarization (Ekstrand-abueg et al., 2016, Lou and Man, 2012, H, A.S.S., K, M.M.C., , 2016, Maio et al., 2015, Rodríguez-Vidal et al., 2019, Kacprzyk et al., 2008, Fu et al., 2015, Wu et al., 2015a, Wu et al., 2015b, Wang et al., 2014). Approach techniques that have been used in real-time summarization are fuzzy-based and machine learning. An example of a method that uses a fuzzy-based approach is the fuzzy logic with classic Zadeh's calculus of linguistically quantified propositions (Kacprzyk et al., 2008) which addresses trend extraction and real-time problems where the results are superior in t-norm evaluation, but weak in semantic problems because the semantic results of other t-norms are unclear and unclear can be understood. Fuzzy Formal Concept Analysis (Fuzzy FCA) (Maio et al., 2015) which addresses semantic and real time problems where the results excel at evaluations in f-measures with optimal recall and comparable precision. An example of a method that uses a machine learning approach is Incremental Short Text Summarization (IncreSTS) by Liu et al., 2015a, Liu et al., 2015b which has better outlier handling, high efficiency, and scalability on target problems. Rank-biased precision-summarization (RBP-SUM) by Rodríguez-Vidal et al. (2019) which has advantages in overcoming redundancy by evaluating using rouge, but this method can only produce extractive summaries.

Text summarization is a formidable challenge in the field of Natural Language Processing (NLP) (Rane and Govilkar, 2019, Shabbir Moiyadi et al., 2016) because it requires precise text analysis such as semantic analysis and lexical analysis to produce a good summary. A good summary, in addition, must contain important information and must be concise but also must consider aspects such as non-redundancy, relevance, coverage, coherence, and readability (Verma et al., 2019). Where to get all these aspects in a summary is a great challenge.

The review of papers on text summarization is important because summarizing extractive techniques has become a very broad research topic and is heading towards maturity (Gupta and Gupta, 2019). Now research has shifted towards abstractive summarization (Gupta and Gupta, 2019) and real-time summarization. This is because abstractive summaries are more complex and complicated than extractive summaries. So extractive summaries are easier to give expected and better results than abstractive summaries (Elrefaiy et al., 2018, Allahyari et al., 2017, Mishra and Gayen, 2018). However, extractive summarization is also still in great demand as evident extractive research still exists in the last two years (Ren et al., 2018, Sanchez-gomez et al., 2018, Yao et al., 2018b, Khan et al., 2019, Qaroush et al., 2019, Anand and Wagh, 2019, Lierde and Chow, 2019). This indicates the possibility that there are still opportunities or loopholes to improve.

A clear literature study is demanded as a means for the advancement of research in the field of text summarization. Where literature studies are generally contained, analyzed, and compared in a review or survey paper. Review paper made by Gupta and Gupta (2019) discusses popular components specifically about abstractive summarizing, such as research trends in the field of abstractive summarization, general description of existing abstractive summarizing techniques, tools, and evaluations. Other reviews were conducted by Abualigah et al. (2020) gave a brief survey of the techniques of text summarization and specifically in Arabic. A survey conducted by Nazari and Mahdavi (2018) discussing text summarization focuses on the approach techniques and methods used in text summarization. Nazari and Mahdavi (2018) grouped approaches to statistics, machine learning, semantic-based, and swarm intelligence. Another survey was conducted by Elrefaiy et al. (2018) which is about summarizing extractive texts that focus on unattended techniques, presents a list of strengths and weaknesses in a comparison table, alluding to a little about evaluations and future trends.

